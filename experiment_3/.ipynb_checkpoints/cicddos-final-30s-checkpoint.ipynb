{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bno-wuuaqwpX",
   "metadata": {
    "id": "bno-wuuaqwpX"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78633f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>frame_time</th>\n",
       "      <th>total_pacotes</th>\n",
       "      <th>total_pacotes_icmp</th>\n",
       "      <th>total_pacotes_udp</th>\n",
       "      <th>total_pacotes_tcp</th>\n",
       "      <th>maior_pacote</th>\n",
       "      <th>menor_pacote</th>\n",
       "      <th>soma_pacotes</th>\n",
       "      <th>total_ips_origem</th>\n",
       "      <th>...</th>\n",
       "      <th>10_coefficient_variation_std_tcp_time_relative</th>\n",
       "      <th>10_lag-1AC_std_tcp_time_relative</th>\n",
       "      <th>10_lag-2AC_std_tcp_time_relative</th>\n",
       "      <th>10_lag-3AC_std_tcp_time_relative</th>\n",
       "      <th>10_skw_mean_tcp_time_relative</th>\n",
       "      <th>10_kurt_mean_tcp_time_relative</th>\n",
       "      <th>10_coefficient_variation_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-1AC_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-2AC_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-3AC_mean_tcp_time_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Nov  3, 2018 12:18:16.583626000 UTC</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>64</td>\n",
       "      <td>346</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nov  3, 2018 12:18:18.506537000 UTC</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>342</td>\n",
       "      <td>60</td>\n",
       "      <td>2832</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Nov  3, 2018 12:18:19.155867000 UTC</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>60</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Nov  3, 2018 12:18:20.270477000 UTC</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>223</td>\n",
       "      <td>60</td>\n",
       "      <td>2938</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2019</td>\n",
       "      <td>Nov  3, 2018 12:51:55.078214000 UTC</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>3732</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2020</td>\n",
       "      <td>Nov  3, 2018 12:51:56.092250000 UTC</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>5068</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2021</td>\n",
       "      <td>Nov  3, 2018 12:51:57.015140000 UTC</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>4032</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2022</td>\n",
       "      <td>Nov  3, 2018 12:51:58.192090000 UTC</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>112</td>\n",
       "      <td>60</td>\n",
       "      <td>3960</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>2023</td>\n",
       "      <td>Nov  3, 2018 12:51:59.195200000 UTC</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>134</td>\n",
       "      <td>60</td>\n",
       "      <td>6726</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2024 rows × 667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                           frame_time  total_pacotes  \\\n",
       "0              0  Nov  3, 2018 12:18:16.583626000 UTC              4   \n",
       "1              1                                    0              0   \n",
       "2              2  Nov  3, 2018 12:18:18.506537000 UTC             31   \n",
       "3              3  Nov  3, 2018 12:18:19.155867000 UTC              6   \n",
       "4              4  Nov  3, 2018 12:18:20.270477000 UTC             28   \n",
       "...          ...                                  ...            ...   \n",
       "2019        2019  Nov  3, 2018 12:51:55.078214000 UTC             46   \n",
       "2020        2020  Nov  3, 2018 12:51:56.092250000 UTC             69   \n",
       "2021        2021  Nov  3, 2018 12:51:57.015140000 UTC             54   \n",
       "2022        2022  Nov  3, 2018 12:51:58.192090000 UTC             56   \n",
       "2023        2023  Nov  3, 2018 12:51:59.195200000 UTC             97   \n",
       "\n",
       "      total_pacotes_icmp  total_pacotes_udp  total_pacotes_tcp  maior_pacote  \\\n",
       "0                      0                  0                  0            94   \n",
       "1                      0                  0                  0             0   \n",
       "2                      0                  0                 18           342   \n",
       "3                      4                  0                  0           130   \n",
       "4                      0                  0                 12           223   \n",
       "...                  ...                ...                ...           ...   \n",
       "2019                   0                  0                 36           150   \n",
       "2020                   4                  0                 54           100   \n",
       "2021                   0                  0                 48           150   \n",
       "2022                   0                  0                 50           112   \n",
       "2023                   0                  0                 93           134   \n",
       "\n",
       "      menor_pacote  soma_pacotes  total_ips_origem  ...  \\\n",
       "0               64           346                 2  ...   \n",
       "1                0             0                 0  ...   \n",
       "2               60          2832                 8  ...   \n",
       "3               60           456                 3  ...   \n",
       "4               60          2938                 6  ...   \n",
       "...            ...           ...               ...  ...   \n",
       "2019            60          3732                11  ...   \n",
       "2020            60          5068                15  ...   \n",
       "2021            60          4032                13  ...   \n",
       "2022            60          3960                11  ...   \n",
       "2023            60          6726                17  ...   \n",
       "\n",
       "      10_coefficient_variation_std_tcp_time_relative  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "...                                              ...   \n",
       "2019                                             NaN   \n",
       "2020                                             NaN   \n",
       "2021                                             NaN   \n",
       "2022                                             NaN   \n",
       "2023                                             NaN   \n",
       "\n",
       "      10_lag-1AC_std_tcp_time_relative  10_lag-2AC_std_tcp_time_relative  \\\n",
       "0                                  NaN                               NaN   \n",
       "1                                  NaN                               NaN   \n",
       "2                                  NaN                               NaN   \n",
       "3                                  NaN                               NaN   \n",
       "4                                  NaN                               NaN   \n",
       "...                                ...                               ...   \n",
       "2019                               NaN                               NaN   \n",
       "2020                               NaN                               NaN   \n",
       "2021                               NaN                               NaN   \n",
       "2022                               NaN                               NaN   \n",
       "2023                               NaN                               NaN   \n",
       "\n",
       "      10_lag-3AC_std_tcp_time_relative  10_skw_mean_tcp_time_relative  \\\n",
       "0                                  NaN                            NaN   \n",
       "1                                  NaN                            NaN   \n",
       "2                                  NaN                            NaN   \n",
       "3                                  NaN                            NaN   \n",
       "4                                  NaN                            NaN   \n",
       "...                                ...                            ...   \n",
       "2019                               NaN                            NaN   \n",
       "2020                               NaN                            NaN   \n",
       "2021                               NaN                            NaN   \n",
       "2022                               NaN                            NaN   \n",
       "2023                               NaN                            NaN   \n",
       "\n",
       "      10_kurt_mean_tcp_time_relative  \\\n",
       "0                                NaN   \n",
       "1                                NaN   \n",
       "2                                NaN   \n",
       "3                                NaN   \n",
       "4                                NaN   \n",
       "...                              ...   \n",
       "2019                             NaN   \n",
       "2020                             NaN   \n",
       "2021                             NaN   \n",
       "2022                             NaN   \n",
       "2023                             NaN   \n",
       "\n",
       "      10_coefficient_variation_mean_tcp_time_relative  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "...                                               ...   \n",
       "2019                                              NaN   \n",
       "2020                                              NaN   \n",
       "2021                                              NaN   \n",
       "2022                                              NaN   \n",
       "2023                                              NaN   \n",
       "\n",
       "      10_lag-1AC_mean_tcp_time_relative  10_lag-2AC_mean_tcp_time_relative  \\\n",
       "0                                   NaN                                NaN   \n",
       "1                                   NaN                                NaN   \n",
       "2                                   NaN                                NaN   \n",
       "3                                   NaN                                NaN   \n",
       "4                                   NaN                                NaN   \n",
       "...                                 ...                                ...   \n",
       "2019                                NaN                                NaN   \n",
       "2020                                NaN                                NaN   \n",
       "2021                                NaN                                NaN   \n",
       "2022                                NaN                                NaN   \n",
       "2023                                NaN                                NaN   \n",
       "\n",
       "      10_lag-3AC_mean_tcp_time_relative  \n",
       "0                                   NaN  \n",
       "1                                   NaN  \n",
       "2                                   NaN  \n",
       "3                                   NaN  \n",
       "4                                   NaN  \n",
       "...                                 ...  \n",
       "2019                                NaN  \n",
       "2020                                NaN  \n",
       "2021                                NaN  \n",
       "2022                                NaN  \n",
       "2023                                NaN  \n",
       "\n",
       "[2024 rows x 667 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_warning_url = \"early_warning_exp_3.csv\"\n",
    "early_warning = pd.read_csv(early_warning_url, sep=\";\")\n",
    "early_warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b473075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ciclabel.csv')['maior_2']\n",
    "\n",
    "init = 202\n",
    "train = 674\n",
    "end = 1484\n",
    "\n",
    "x_train = df[init:train]\n",
    "x_test = df[train:end]\n",
    "y_real = label[train:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63cdf93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(gamma='auto', kernel='sigmoid', nu=0.05)\n",
      "[[685  17]\n",
      " [106   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8660    0.9758    0.9176       702\n",
      "           1     0.1053    0.0185    0.0315       108\n",
      "\n",
      "    accuracy                         0.8481       810\n",
      "   macro avg     0.4856    0.4972    0.4746       810\n",
      "weighted avg     0.7646    0.8481    0.7995       810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fica = FastICA(n_components=3, random_state=0).fit(x_train)\n",
    "train_fica  = fica.transform(x_train)\n",
    "clf = OneClassSVM(gamma='auto', kernel='sigmoid', nu=0.05).fit(train_fica)\n",
    "novo_test = []\n",
    "preds = []\n",
    "for i in range (0,27):\n",
    "    comeco = i*30\n",
    "    final = (i+1)*30\n",
    "    if(final > end):\n",
    "        final = end\n",
    "    y_test = clf.predict(fica.transform(x_test[comeco:final]))\n",
    "    y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "    preds += y_test_final\n",
    "    \n",
    "print(clf)\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5357f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(gamma='auto', kernel='linear', nu=0.32)\n",
      "[[676  26]\n",
      " [102   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8689    0.9630    0.9135       702\n",
      "           1     0.1875    0.0556    0.0857       108\n",
      "\n",
      "    accuracy                         0.8420       810\n",
      "   macro avg     0.5282    0.5093    0.4996       810\n",
      "weighted avg     0.7780    0.8420    0.8031       810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fa = FactorAnalysis(n_components=3, random_state=0).fit(x_train)\n",
    "train_fa  = fa.transform(x_train)\n",
    "clf = OneClassSVM(gamma='auto', kernel='linear', nu=0.32).fit(train_fa)\n",
    "novo_test = []\n",
    "preds = []\n",
    "for i in range (0,27):\n",
    "    comeco = i*30\n",
    "    final = (i+1)*30\n",
    "    if(final > end):\n",
    "        final = end\n",
    "    y_test = clf.predict(fa.transform(x_test[comeco:final]))\n",
    "    y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "    preds += y_test_final\n",
    "    \n",
    "print(clf)\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b794fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM(gamma='auto', kernel='sigmoid', nu=0.05)\n",
      "[[684  18]\n",
      " [105   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8669    0.9744    0.9175       702\n",
      "           1     0.1429    0.0278    0.0465       108\n",
      "\n",
      "    accuracy                         0.8481       810\n",
      "   macro avg     0.5049    0.5011    0.4820       810\n",
      "weighted avg     0.7704    0.8481    0.8014       810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=3, random_state=0).fit(x_train)\n",
    "train_pca  = pca.transform(x_train)\n",
    "clf = OneClassSVM(gamma='auto', kernel='sigmoid', nu=0.05).fit(train_pca)\n",
    "novo_test = []\n",
    "preds = []\n",
    "for i in range (0,27):\n",
    "    comeco = i*30\n",
    "    final = (i+1)*30\n",
    "    if(final > end):\n",
    "        final = end\n",
    "    y_test = clf.predict(pca.transform(x_test[comeco:final]))\n",
    "    y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "    preds += y_test_final\n",
    "    \n",
    "print(clf)\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8341bc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1]\n",
      "[[1023   80]\n",
      " [ 164   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8618    0.9275    0.8934      1103\n",
      "           1     0.1579    0.0838    0.1095       179\n",
      "\n",
      "    accuracy                         0.8097      1282\n",
      "   macro avg     0.5099    0.5056    0.5015      1282\n",
      "weighted avg     0.7635    0.8097    0.7840      1282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = '10'\n",
    "colunas = [file+'_kurt_total_ips_origem',\n",
    "           file+'_skw_total_ips_origem',\n",
    "           file+'_coefficient_variation_total_ips_origem',\n",
    "           file+'_kurt_total_ips_destino',\n",
    "           file+'_skw_total_ips_destino',\n",
    "           file+'_coefficient_variation_total_ips_destino',\n",
    "           file+'_kurt_total_pacotes',\n",
    "           file+'_skw_total_pacotes',\n",
    "           file+'_coefficient_variation_total_pacotes',]\n",
    "\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ciclabel.csv')['maior_2']\n",
    "\n",
    "init = 202\n",
    "end = 1484\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "limiar = 50\n",
    "\n",
    "for i in range(0, 43):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "        \n",
    "        \n",
    "    array_kernel = ['linear' , 'poly' , 'rbf' ,  ] # 'precomputed','sigmoid'\n",
    "    result = []\n",
    "    \n",
    "    nu_atual = 0.05\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= 0.15:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x_test[comeco:final])\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)       \n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "        \n",
    "        \n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= 0.15:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1)\n",
    "            y_test = clf.fit_predict(x_test[comeco:final])\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)       \n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "    array_algorithm = ['auto', 'ball_tree', 'kd_tree','brute']\n",
    "    \n",
    "    nu_atual = 0.05\n",
    "    for c in array_algorithm:\n",
    "        while nu_atual <= 0.15:\n",
    "            clf = LocalOutlierFactor(n_neighbors=2, algorithm = c)\n",
    "            y_test = clf.fit_predict(x_test[comeco:final])\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)       \n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "        \n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "    \n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "\n",
    "print(preds)\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962d753c-84a0-45ed-9478-3e37bf408a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[1096    7]\n",
      " [ 177    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8610    0.9937    0.9226      1103\n",
      "           1     0.2222    0.0112    0.0213       179\n",
      "\n",
      "    accuracy                         0.8565      1282\n",
      "   macro avg     0.5416    0.5024    0.4719      1282\n",
      "weighted avg     0.7718    0.8565    0.7967      1282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = '10'\n",
    "colunas = [file+'_kurt_total_ips_origem',\n",
    "           file+'_skw_total_ips_origem',\n",
    "           file+'_coefficient_variation_total_ips_origem',\n",
    "           file+'_kurt_total_ips_destino',\n",
    "           file+'_skw_total_ips_destino',\n",
    "           file+'_coefficient_variation_total_ips_destino',\n",
    "           file+'_kurt_total_pacotes',\n",
    "           file+'_skw_total_pacotes',\n",
    "           file+'_coefficient_variation_total_pacotes',]\n",
    "\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ciclabel.csv')['maior_2']\n",
    "\n",
    "init = 202\n",
    "end = 1484\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "limiar = 70\n",
    "\n",
    "for i in range(0, 43):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "        \n",
    "        \n",
    "    array_kernel = ['linear' , 'poly' , 'rbf' ,  ] # 'precomputed','sigmoid'\n",
    "    result = []\n",
    "    \n",
    "    x = FactorAnalysis(n_components=3, random_state=0).fit_transform(x_test[comeco:final])\n",
    "    #x = FastICA(n_components=9, random_state=0).fit_transform(x_test[comeco:final])\n",
    "    # x = x_test[comeco:final]\n",
    "    \n",
    "    nu_atual = 0.05\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= 0.15:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)       \n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "        \n",
    "        \n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= 0.15:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)       \n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "    array_algorithm = ['auto', 'ball_tree', 'kd_tree','brute']\n",
    "    \n",
    "    nu_atual = 0.05\n",
    "    for c in array_algorithm:\n",
    "        while nu_atual <= 0.15:\n",
    "            clf = LocalOutlierFactor(n_neighbors=2, algorithm = c)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)       \n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "        \n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "    \n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "\n",
    "print(preds)\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e21fc1-4ff2-4066-b10e-b7f4efdd63f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste com  1  features\n",
      "limiarrrrrrrrrr 120.0 240\n",
      "[[1077   26]\n",
      " [ 177    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8589    0.9764    0.9139      1103\n",
      "           1     0.0714    0.0112    0.0193       179\n",
      "\n",
      "    accuracy                         0.8417      1282\n",
      "   macro avg     0.4651    0.4938    0.4666      1282\n",
      "weighted avg     0.7489    0.8417    0.7890      1282\n",
      "\n",
      "teste com  2  features\n",
      "limiarrrrrrrrrr 120.0 240\n",
      "[[1097    6]\n",
      " [ 175    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8624    0.9946    0.9238      1103\n",
      "           1     0.4000    0.0223    0.0423       179\n",
      "\n",
      "    accuracy                         0.8588      1282\n",
      "   macro avg     0.6312    0.5085    0.4831      1282\n",
      "weighted avg     0.7979    0.8588    0.8007      1282\n",
      "\n",
      "teste com  3  features\n",
      "limiarrrrrrrrrr 120.0 240\n",
      "[[1098    5]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8598    0.9955    0.9227      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8565      1282\n",
      "   macro avg     0.4299    0.4977    0.4613      1282\n",
      "weighted avg     0.7398    0.8565    0.7939      1282\n",
      "\n",
      "teste com  4  features\n",
      "limiarrrrrrrrrr 120.0 240\n",
      "[[1099    4]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8599    0.9964    0.9231      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8573      1282\n",
      "   macro avg     0.4300    0.4982    0.4616      1282\n",
      "weighted avg     0.7399    0.8573    0.7942      1282\n",
      "\n",
      "teste com  5  features\n",
      "limiarrrrrrrrrr 120.0 240\n",
      "[[1101    2]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8602    0.9982    0.9240      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8588      1282\n",
      "   macro avg     0.4301    0.4991    0.4620      1282\n",
      "weighted avg     0.7401    0.8588    0.7950      1282\n",
      "\n",
      "teste com  6  features\n",
      "limiarrrrrrrrrr 120.0 240\n",
      "[[1102    1]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8603    0.9991    0.9245      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8596      1282\n",
      "   macro avg     0.4301    0.4995    0.4622      1282\n",
      "weighted avg     0.7402    0.8596    0.7954      1282\n",
      "\n",
      "teste com  7  features\n",
      "limiarrrrrrrrrr 120.0 240\n",
      "[[1101    2]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8602    0.9982    0.9240      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8588      1282\n",
      "   macro avg     0.4301    0.4991    0.4620      1282\n",
      "weighted avg     0.7401    0.8588    0.7950      1282\n",
      "\n",
      "teste com  8  features\n",
      "limiarrrrrrrrrr 120.0 240\n",
      "[[1101    2]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8602    0.9982    0.9240      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8588      1282\n",
      "   macro avg     0.4301    0.4991    0.4620      1282\n",
      "weighted avg     0.7401    0.8588    0.7950      1282\n",
      "\n",
      "teste com  9  features\n",
      "limiarrrrrrrrrr 120.0 240\n",
      "[[1103    0]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8604    1.0000    0.9249      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8604      1282\n",
      "   macro avg     0.4302    0.5000    0.4625      1282\n",
      "weighted avg     0.7402    0.8604    0.7958      1282\n",
      "\n",
      "teste com  10  features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limiarrrrrrrrrr 120.0 240\n",
      "[[1103    0]\n",
      " [ 178    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8610    1.0000    0.9253      1103\n",
      "           1     1.0000    0.0056    0.0111       179\n",
      "\n",
      "    accuracy                         0.8612      1282\n",
      "   macro avg     0.9305    0.5028    0.4682      1282\n",
      "weighted avg     0.8804    0.8612    0.7977      1282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in range(1,11):\n",
    "    print(\"teste com \", feature, ' features')\n",
    "    colunas = early_warning.columns[361:]\n",
    "\n",
    "    df = early_warning[colunas]\n",
    "    df = df.fillna(0)\n",
    "    label = pd.read_csv('ciclabel.csv')['maior_2']\n",
    "\n",
    "    init = 202\n",
    "    end = 1484\n",
    "\n",
    "    x_test = df[init:end]\n",
    "    y_real = label[init:end]\n",
    "    tamanho = 30\n",
    "    preds = []\n",
    "\n",
    "    qtde_models = 0.35\n",
    "    for i in range(0, 43):\n",
    "        comeco = i*tamanho\n",
    "        final = (i+1)*tamanho\n",
    "        if(final > len(y_real)):\n",
    "            tamanho = len(y_real) - (final - tamanho) \n",
    "            final = len(y_real)\n",
    "\n",
    "        models = 0    \n",
    "        array_kernel = ['linear' , 'poly' , 'rbf' ,'sigmoid'  ] # 'precomputed'\n",
    "        result = []\n",
    "\n",
    "        x = FactorAnalysis(n_components=feature, random_state=0).fit_transform(x_test[comeco:final])\n",
    "        # = FastICA(n_components=5, random_state=0).fit_transform(x_test[comeco:final])\n",
    "        # x = x_test[comeco:final]\n",
    "\n",
    "        nu_atual = 0.05\n",
    "        for c in array_kernel:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)\n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.05\n",
    "\n",
    "\n",
    "        learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "        nu_atual = 0.05\n",
    "        for c in learning_rate:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)  \n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.05\n",
    "\n",
    "        cols = [i for i in range(0, tamanho)]\n",
    "        df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "        limiar = models*0.5\n",
    "        #print('limiarrrrrrrrrr', limiar, models)\n",
    "\n",
    "        for col in cols:\n",
    "            preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "\n",
    "    #print(preds)\n",
    "    print('limiarrrrrrrrrr', limiar, models)\n",
    "    print(confusion_matrix(y_real, preds))\n",
    "    print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe324d7-f482-4165-9f67-2d8fdd0a7ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste com  1  features\n",
      "limiarrrrrrrrrr 135.0 270\n",
      "[[1077   26]\n",
      " [ 175    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8602    0.9764    0.9146      1103\n",
      "           1     0.1333    0.0223    0.0383       179\n",
      "\n",
      "    accuracy                         0.8432      1282\n",
      "   macro avg     0.4968    0.4994    0.4765      1282\n",
      "weighted avg     0.7587    0.8432    0.7923      1282\n",
      "\n",
      "teste com  2  features\n",
      "limiarrrrrrrrrr 135.0 270\n",
      "[[1088   15]\n",
      " [ 176    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8608    0.9864    0.9193      1103\n",
      "           1     0.1667    0.0168    0.0305       179\n",
      "\n",
      "    accuracy                         0.8510      1282\n",
      "   macro avg     0.5137    0.5016    0.4749      1282\n",
      "weighted avg     0.7638    0.8510    0.7952      1282\n",
      "\n",
      "teste com  3  features\n",
      "limiarrrrrrrrrr 135.0 270\n",
      "[[1101    2]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8602    0.9982    0.9240      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8588      1282\n",
      "   macro avg     0.4301    0.4991    0.4620      1282\n",
      "weighted avg     0.7401    0.8588    0.7950      1282\n",
      "\n",
      "teste com  4  features\n",
      "limiarrrrrrrrrr 135.0 270\n",
      "[[1099    4]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8599    0.9964    0.9231      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8573      1282\n",
      "   macro avg     0.4300    0.4982    0.4616      1282\n",
      "weighted avg     0.7399    0.8573    0.7942      1282\n",
      "\n",
      "teste com  5  features\n",
      "limiarrrrrrrrrr 135.0 270\n",
      "[[1102    1]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8603    0.9991    0.9245      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8596      1282\n",
      "   macro avg     0.4301    0.4995    0.4622      1282\n",
      "weighted avg     0.7402    0.8596    0.7954      1282\n",
      "\n",
      "teste com  6  features\n",
      "limiarrrrrrrrrr 135.0 270\n",
      "[[1103    0]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8604    1.0000    0.9249      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8604      1282\n",
      "   macro avg     0.4302    0.5000    0.4625      1282\n",
      "weighted avg     0.7402    0.8604    0.7958      1282\n",
      "\n",
      "teste com  7  features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limiarrrrrrrrrr 135.0 270\n",
      "[[1102    1]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8603    0.9991    0.9245      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8596      1282\n",
      "   macro avg     0.4301    0.4995    0.4622      1282\n",
      "weighted avg     0.7402    0.8596    0.7954      1282\n",
      "\n",
      "teste com  8  features\n",
      "limiarrrrrrrrrr 135.0 270\n",
      "[[1103    0]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8604    1.0000    0.9249      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8604      1282\n",
      "   macro avg     0.4302    0.5000    0.4625      1282\n",
      "weighted avg     0.7402    0.8604    0.7958      1282\n",
      "\n",
      "teste com  9  features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limiarrrrrrrrrr 135.0 270\n",
      "[[1103    0]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8604    1.0000    0.9249      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8604      1282\n",
      "   macro avg     0.4302    0.5000    0.4625      1282\n",
      "weighted avg     0.7402    0.8604    0.7958      1282\n",
      "\n",
      "teste com  10  features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limiarrrrrrrrrr 135.0 270\n",
      "[[1103    0]\n",
      " [ 178    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8610    1.0000    0.9253      1103\n",
      "           1     1.0000    0.0056    0.0111       179\n",
      "\n",
      "    accuracy                         0.8612      1282\n",
      "   macro avg     0.9305    0.5028    0.4682      1282\n",
      "weighted avg     0.8804    0.8612    0.7977      1282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in range(1,10):\n",
    "    print(\"teste com \", feature, ' features')\n",
    "    colunas = early_warning.columns[361:]\n",
    "\n",
    "    df = early_warning[colunas]\n",
    "    df = df.fillna(0)\n",
    "    label = pd.read_csv('ciclabel.csv')['maior_2']\n",
    "\n",
    "    init = 202\n",
    "    end = 1484\n",
    "\n",
    "    x_test = df[init:end]\n",
    "    y_real = label[init:end]\n",
    "    tamanho = 30\n",
    "    preds = []\n",
    "\n",
    "    qtde_models = 0.35\n",
    "    for i in range(0, 43):\n",
    "        comeco = i*tamanho\n",
    "        final = (i+1)*tamanho\n",
    "        if(final > len(y_real)):\n",
    "            tamanho = len(y_real) - (final - tamanho) \n",
    "            final = len(y_real)\n",
    "\n",
    "        models = 0    \n",
    "        array_kernel = ['linear' , 'poly' , 'rbf' ,'sigmoid'  ] # 'precomputed'\n",
    "        result = []\n",
    "\n",
    "        x = FactorAnalysis(n_components=feature, random_state=0).fit_transform(x_test[comeco:final])\n",
    "        # = FastICA(n_components=5, random_state=0).fit_transform(x_test[comeco:final])\n",
    "        # x = x_test[comeco:final]\n",
    "\n",
    "        nu_atual = 0.05\n",
    "        for c in array_kernel:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)\n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.05\n",
    "\n",
    "\n",
    "        learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "        nu_atual = 0.05\n",
    "        for c in learning_rate:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)  \n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.05\n",
    "\n",
    "        contamination_atual = 0.05\n",
    "        while contamination_atual <= qtde_models:\n",
    "            clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            contamination_atual += 0.01\n",
    "\n",
    "\n",
    "        cols = [i for i in range(0, tamanho)]\n",
    "        df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "        limiar = models*0.5\n",
    "        #print('limiarrrrrrrrrr', limiar, models)\n",
    "\n",
    "        for col in cols:\n",
    "            preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "\n",
    "    #print(preds)\n",
    "    print('limiarrrrrrrrrr', limiar, models)\n",
    "    print(confusion_matrix(y_real, preds))\n",
    "    print(classification_report(y_real, preds, digits = 4)) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
