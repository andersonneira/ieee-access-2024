{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bno-wuuaqwpX",
   "metadata": {
    "id": "bno-wuuaqwpX"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78633f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>frame_time</th>\n",
       "      <th>total_pacotes</th>\n",
       "      <th>total_pacotes_icmp</th>\n",
       "      <th>total_pacotes_udp</th>\n",
       "      <th>total_pacotes_tcp</th>\n",
       "      <th>maior_pacote</th>\n",
       "      <th>menor_pacote</th>\n",
       "      <th>soma_pacotes</th>\n",
       "      <th>total_ips_origem</th>\n",
       "      <th>...</th>\n",
       "      <th>10_coefficient_variation_std_tcp_time_relative</th>\n",
       "      <th>10_lag-1AC_std_tcp_time_relative</th>\n",
       "      <th>10_lag-2AC_std_tcp_time_relative</th>\n",
       "      <th>10_lag-3AC_std_tcp_time_relative</th>\n",
       "      <th>10_skw_mean_tcp_time_relative</th>\n",
       "      <th>10_kurt_mean_tcp_time_relative</th>\n",
       "      <th>10_coefficient_variation_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-1AC_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-2AC_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-3AC_mean_tcp_time_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Nov  3, 2018 12:18:16.583626000 UTC</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>64</td>\n",
       "      <td>346</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nov  3, 2018 12:18:18.506537000 UTC</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>342</td>\n",
       "      <td>60</td>\n",
       "      <td>2832</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Nov  3, 2018 12:18:19.155867000 UTC</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>60</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Nov  3, 2018 12:18:20.270477000 UTC</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>223</td>\n",
       "      <td>60</td>\n",
       "      <td>2938</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2019</td>\n",
       "      <td>Nov  3, 2018 12:51:55.078214000 UTC</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>3732</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2020</td>\n",
       "      <td>Nov  3, 2018 12:51:56.092250000 UTC</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>5068</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2021</td>\n",
       "      <td>Nov  3, 2018 12:51:57.015140000 UTC</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>4032</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2022</td>\n",
       "      <td>Nov  3, 2018 12:51:58.192090000 UTC</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>112</td>\n",
       "      <td>60</td>\n",
       "      <td>3960</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>2023</td>\n",
       "      <td>Nov  3, 2018 12:51:59.195200000 UTC</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>134</td>\n",
       "      <td>60</td>\n",
       "      <td>6726</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2024 rows Ã— 667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                           frame_time  total_pacotes  \\\n",
       "0              0  Nov  3, 2018 12:18:16.583626000 UTC              4   \n",
       "1              1                                    0              0   \n",
       "2              2  Nov  3, 2018 12:18:18.506537000 UTC             31   \n",
       "3              3  Nov  3, 2018 12:18:19.155867000 UTC              6   \n",
       "4              4  Nov  3, 2018 12:18:20.270477000 UTC             28   \n",
       "...          ...                                  ...            ...   \n",
       "2019        2019  Nov  3, 2018 12:51:55.078214000 UTC             46   \n",
       "2020        2020  Nov  3, 2018 12:51:56.092250000 UTC             69   \n",
       "2021        2021  Nov  3, 2018 12:51:57.015140000 UTC             54   \n",
       "2022        2022  Nov  3, 2018 12:51:58.192090000 UTC             56   \n",
       "2023        2023  Nov  3, 2018 12:51:59.195200000 UTC             97   \n",
       "\n",
       "      total_pacotes_icmp  total_pacotes_udp  total_pacotes_tcp  maior_pacote  \\\n",
       "0                      0                  0                  0            94   \n",
       "1                      0                  0                  0             0   \n",
       "2                      0                  0                 18           342   \n",
       "3                      4                  0                  0           130   \n",
       "4                      0                  0                 12           223   \n",
       "...                  ...                ...                ...           ...   \n",
       "2019                   0                  0                 36           150   \n",
       "2020                   4                  0                 54           100   \n",
       "2021                   0                  0                 48           150   \n",
       "2022                   0                  0                 50           112   \n",
       "2023                   0                  0                 93           134   \n",
       "\n",
       "      menor_pacote  soma_pacotes  total_ips_origem  ...  \\\n",
       "0               64           346                 2  ...   \n",
       "1                0             0                 0  ...   \n",
       "2               60          2832                 8  ...   \n",
       "3               60           456                 3  ...   \n",
       "4               60          2938                 6  ...   \n",
       "...            ...           ...               ...  ...   \n",
       "2019            60          3732                11  ...   \n",
       "2020            60          5068                15  ...   \n",
       "2021            60          4032                13  ...   \n",
       "2022            60          3960                11  ...   \n",
       "2023            60          6726                17  ...   \n",
       "\n",
       "      10_coefficient_variation_std_tcp_time_relative  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "...                                              ...   \n",
       "2019                                             NaN   \n",
       "2020                                             NaN   \n",
       "2021                                             NaN   \n",
       "2022                                             NaN   \n",
       "2023                                             NaN   \n",
       "\n",
       "      10_lag-1AC_std_tcp_time_relative  10_lag-2AC_std_tcp_time_relative  \\\n",
       "0                                  NaN                               NaN   \n",
       "1                                  NaN                               NaN   \n",
       "2                                  NaN                               NaN   \n",
       "3                                  NaN                               NaN   \n",
       "4                                  NaN                               NaN   \n",
       "...                                ...                               ...   \n",
       "2019                               NaN                               NaN   \n",
       "2020                               NaN                               NaN   \n",
       "2021                               NaN                               NaN   \n",
       "2022                               NaN                               NaN   \n",
       "2023                               NaN                               NaN   \n",
       "\n",
       "      10_lag-3AC_std_tcp_time_relative  10_skw_mean_tcp_time_relative  \\\n",
       "0                                  NaN                            NaN   \n",
       "1                                  NaN                            NaN   \n",
       "2                                  NaN                            NaN   \n",
       "3                                  NaN                            NaN   \n",
       "4                                  NaN                            NaN   \n",
       "...                                ...                            ...   \n",
       "2019                               NaN                            NaN   \n",
       "2020                               NaN                            NaN   \n",
       "2021                               NaN                            NaN   \n",
       "2022                               NaN                            NaN   \n",
       "2023                               NaN                            NaN   \n",
       "\n",
       "      10_kurt_mean_tcp_time_relative  \\\n",
       "0                                NaN   \n",
       "1                                NaN   \n",
       "2                                NaN   \n",
       "3                                NaN   \n",
       "4                                NaN   \n",
       "...                              ...   \n",
       "2019                             NaN   \n",
       "2020                             NaN   \n",
       "2021                             NaN   \n",
       "2022                             NaN   \n",
       "2023                             NaN   \n",
       "\n",
       "      10_coefficient_variation_mean_tcp_time_relative  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "...                                               ...   \n",
       "2019                                              NaN   \n",
       "2020                                              NaN   \n",
       "2021                                              NaN   \n",
       "2022                                              NaN   \n",
       "2023                                              NaN   \n",
       "\n",
       "      10_lag-1AC_mean_tcp_time_relative  10_lag-2AC_mean_tcp_time_relative  \\\n",
       "0                                   NaN                                NaN   \n",
       "1                                   NaN                                NaN   \n",
       "2                                   NaN                                NaN   \n",
       "3                                   NaN                                NaN   \n",
       "4                                   NaN                                NaN   \n",
       "...                                 ...                                ...   \n",
       "2019                                NaN                                NaN   \n",
       "2020                                NaN                                NaN   \n",
       "2021                                NaN                                NaN   \n",
       "2022                                NaN                                NaN   \n",
       "2023                                NaN                                NaN   \n",
       "\n",
       "      10_lag-3AC_mean_tcp_time_relative  \n",
       "0                                   NaN  \n",
       "1                                   NaN  \n",
       "2                                   NaN  \n",
       "3                                   NaN  \n",
       "4                                   NaN  \n",
       "...                                 ...  \n",
       "2019                                NaN  \n",
       "2020                                NaN  \n",
       "2021                                NaN  \n",
       "2022                                NaN  \n",
       "2023                                NaN  \n",
       "\n",
       "[2024 rows x 667 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_warning_url = \"early_warning_exp_3.csv\"\n",
    "early_warning = pd.read_csv(early_warning_url, sep=\";\")\n",
    "early_warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e21fc1-4ff2-4066-b10e-b7f4efdd63f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1097    6]\n",
      " [ 175    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8624    0.9946    0.9238      1103\n",
      "           1     0.4000    0.0223    0.0423       179\n",
      "\n",
      "    accuracy                         0.8588      1282\n",
      "   macro avg     0.6312    0.5085    0.4831      1282\n",
      "weighted avg     0.7979    0.8588    0.8007      1282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ciclabel.csv')['maior_2']\n",
    "\n",
    "init = 202\n",
    "end = 1484\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "\n",
    "qtde_models = 0.35\n",
    "for i in range(0, 43):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['linear' , 'poly' , 'rbf' ,'sigmoid'  ]\n",
    "    result = []\n",
    "\n",
    "    x = FactorAnalysis(n_components=2, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            models = models + 1\n",
    "            result.append(y_test_final)  \n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "    \n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    limiar = models*0.5\n",
    "\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c964813-907e-4229-8863-291ac1feeec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1088   15]\n",
      " [ 176    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8608    0.9864    0.9193      1103\n",
      "           1     0.1667    0.0168    0.0305       179\n",
      "\n",
      "    accuracy                         0.8510      1282\n",
      "   macro avg     0.5137    0.5016    0.4749      1282\n",
      "weighted avg     0.7638    0.8510    0.7952      1282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ciclabel.csv')['maior_2']\n",
    "\n",
    "init = 202\n",
    "end = 1484\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "\n",
    "qtde_models = 0.35\n",
    "for i in range(0, 43):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['linear' , 'poly' , 'rbf' ,'sigmoid'  ]\n",
    "    result = []\n",
    "\n",
    "    x = FactorAnalysis(n_components=2, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            models = models + 1\n",
    "            result.append(y_test_final)  \n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "    contamination_atual = 0.05\n",
    "    while contamination_atual <= qtde_models:\n",
    "        clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "        y_test = clf.fit_predict(x)\n",
    "        y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "        result.append(y_test_final)  \n",
    "        models = models + 1\n",
    "        contamination_atual += 0.01\n",
    "\n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    limiar = models*0.5\n",
    "\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf359ad-022f-4cd2-8c72-8455b79fcbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  1\n",
      "[[1081   22]\n",
      " [ 174    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8614    0.9801    0.9169      1103\n",
      "           1     0.1852    0.0279    0.0485       179\n",
      "\n",
      "    accuracy                         0.8471      1282\n",
      "   macro avg     0.5233    0.5040    0.4827      1282\n",
      "weighted avg     0.7669    0.8471    0.7956      1282\n",
      "\n",
      "total of features:  2\n",
      "[[1066   37]\n",
      " [ 173    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8604    0.9665    0.9103      1103\n",
      "           1     0.1395    0.0335    0.0541       179\n",
      "\n",
      "    accuracy                         0.8362      1282\n",
      "   macro avg     0.5000    0.5000    0.4822      1282\n",
      "weighted avg     0.7597    0.8362    0.7908      1282\n",
      "\n",
      "total of features:  3\n",
      "[[1052   51]\n",
      " [ 177    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8560    0.9538    0.9022      1103\n",
      "           1     0.0377    0.0112    0.0172       179\n",
      "\n",
      "    accuracy                         0.8222      1282\n",
      "   macro avg     0.4469    0.4825    0.4597      1282\n",
      "weighted avg     0.7417    0.8222    0.7787      1282\n",
      "\n",
      "total of features:  4\n",
      "[[1053   50]\n",
      " [ 172    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8596    0.9547    0.9046      1103\n",
      "           1     0.1228    0.0391    0.0593       179\n",
      "\n",
      "    accuracy                         0.8268      1282\n",
      "   macro avg     0.4912    0.4969    0.4820      1282\n",
      "weighted avg     0.7567    0.8268    0.7866      1282\n",
      "\n",
      "total of features:  5\n",
      "[[1063   40]\n",
      " [ 173    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8600    0.9637    0.9089      1103\n",
      "           1     0.1304    0.0335    0.0533       179\n",
      "\n",
      "    accuracy                         0.8339      1282\n",
      "   macro avg     0.4952    0.4986    0.4811      1282\n",
      "weighted avg     0.7582    0.8339    0.7895      1282\n",
      "\n",
      "total of features:  6\n",
      "[[1049   54]\n",
      " [ 173    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8584    0.9510    0.9024      1103\n",
      "           1     0.1000    0.0335    0.0502       179\n",
      "\n",
      "    accuracy                         0.8229      1282\n",
      "   macro avg     0.4792    0.4923    0.4763      1282\n",
      "weighted avg     0.7525    0.8229    0.7834      1282\n",
      "\n",
      "total of features:  7\n",
      "[[1059   44]\n",
      " [ 169   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8624    0.9601    0.9086      1103\n",
      "           1     0.1852    0.0559    0.0858       179\n",
      "\n",
      "    accuracy                         0.8339      1282\n",
      "   macro avg     0.5238    0.5080    0.4972      1282\n",
      "weighted avg     0.7678    0.8339    0.7937      1282\n",
      "\n",
      "total of features:  8\n",
      "[[1053   50]\n",
      " [ 168   11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8624    0.9547    0.9062      1103\n",
      "           1     0.1803    0.0615    0.0917       179\n",
      "\n",
      "    accuracy                         0.8300      1282\n",
      "   macro avg     0.5214    0.5081    0.4989      1282\n",
      "weighted avg     0.7672    0.8300    0.7925      1282\n",
      "\n",
      "total of features:  9\n",
      "[[1046   57]\n",
      " [ 168   11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8616    0.9483    0.9029      1103\n",
      "           1     0.1618    0.0615    0.0891       179\n",
      "\n",
      "    accuracy                         0.8245      1282\n",
      "   macro avg     0.5117    0.5049    0.4960      1282\n",
      "weighted avg     0.7639    0.8245    0.7893      1282\n",
      "\n",
      "total of features:  10\n",
      "[[1056   47]\n",
      " [ 167   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8635    0.9574    0.9080      1103\n",
      "           1     0.2034    0.0670    0.1008       179\n",
      "\n",
      "    accuracy                         0.8331      1282\n",
      "   macro avg     0.5334    0.5122    0.5044      1282\n",
      "weighted avg     0.7713    0.8331    0.7953      1282\n",
      "\n",
      "total of features:  11\n",
      "[[1049   54]\n",
      " [ 168   11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8620    0.9510    0.9043      1103\n",
      "           1     0.1692    0.0615    0.0902       179\n",
      "\n",
      "    accuracy                         0.8268      1282\n",
      "   macro avg     0.5156    0.5062    0.4972      1282\n",
      "weighted avg     0.7652    0.8268    0.7906      1282\n",
      "\n",
      "total of features:  12\n",
      "[[1053   50]\n",
      " [ 167   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8631    0.9547    0.9066      1103\n",
      "           1     0.1935    0.0670    0.0996       179\n",
      "\n",
      "    accuracy                         0.8307      1282\n",
      "   macro avg     0.5283    0.5109    0.5031      1282\n",
      "weighted avg     0.7696    0.8307    0.7939      1282\n",
      "\n",
      "total of features:  13\n",
      "[[1047   56]\n",
      " [ 165   14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8639    0.9492    0.9045      1103\n",
      "           1     0.2000    0.0782    0.1124       179\n",
      "\n",
      "    accuracy                         0.8276      1282\n",
      "   macro avg     0.5319    0.5137    0.5085      1282\n",
      "weighted avg     0.7712    0.8276    0.7939      1282\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m contamination_atual \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m qtde_models:\n\u001b[1;32m     57\u001b[0m     clf \u001b[38;5;241m=\u001b[39m EllipticEnvelope(contamination \u001b[38;5;241m=\u001b[39m contamination_atual,support_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     y_test_final \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m y_test]\n\u001b[1;32m     60\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(y_test_final)  \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1036\u001b[0m, in \u001b[0;36mOutlierMixin.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Perform fit on X and returns labels for X.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \n\u001b[1;32m   1020\u001b[0m \u001b[38;5;124;03mReturns -1 for outliers and 1 for inliers.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;124;03m    1 for inliers, -1 for outliers.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m# override for transductive outlier detectors like LocalOulierFactor\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/covariance/_elliptic_envelope.py:184\u001b[0m, in \u001b[0;36mEllipticEnvelope.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the EllipticEnvelope model.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_, \u001b[38;5;241m100.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontamination)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:751\u001b[0m, in \u001b[0;36mMinCovDet.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    747\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    748\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe covariance matrix associated to your dataset is not full rank\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    749\u001b[0m     )\n\u001b[1;32m    750\u001b[0m \u001b[38;5;66;03m# compute and store raw estimates\u001b[39;00m\n\u001b[0;32m--> 751\u001b[0m raw_location, raw_covariance, raw_support, raw_dist \u001b[38;5;241m=\u001b[39m \u001b[43mfast_mcd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43msupport_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_fraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcov_computation_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nonrobust_covariance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massume_centered:\n\u001b[1;32m    758\u001b[0m     raw_location \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_features)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:553\u001b[0m, in \u001b[0;36mfast_mcd\u001b[0;34m(X, support_fraction, cov_computation_method, random_state)\u001b[0m\n\u001b[1;32m    551\u001b[0m n_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m    552\u001b[0m n_best \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m--> 553\u001b[0m locations_best, covariances_best, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mselect_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcov_computation_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_computation_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# 2. Select the best couple on the full dataset amongst the 10\u001b[39;00m\n\u001b[1;32m    563\u001b[0m locations_full, covariances_full, supports_full, d \u001b[38;5;241m=\u001b[39m select_candidates(\n\u001b[1;32m    564\u001b[0m     X,\n\u001b[1;32m    565\u001b[0m     n_support,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:320\u001b[0m, in \u001b[0;36mselect_candidates\u001b[0;34m(X, n_support, n_trials, select, n_iter, verbose, cov_computation_method, random_state)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_from_estimates:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# perform `n_trials` computations from random initial supports\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_trials):\n\u001b[1;32m    319\u001b[0m         all_estimates\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 320\u001b[0m             \u001b[43m_c_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m                \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m                \u001b[49m\u001b[43mremaining_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcov_computation_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_computation_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;66;03m# perform computations from every given initial estimates\u001b[39;00m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_trials):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:171\u001b[0m, in \u001b[0;36m_c_step\u001b[0;34m(X, n_support, random_state, remaining_iterations, initial_estimates, verbose, cov_computation_method)\u001b[0m\n\u001b[1;32m    168\u001b[0m     remaining_iterations \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    170\u001b[0m previous_dist \u001b[38;5;241m=\u001b[39m dist\n\u001b[0;32m--> 171\u001b[0m dist \u001b[38;5;241m=\u001b[39m (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m (X \u001b[38;5;241m-\u001b[39m location))\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Check if best fit already found (det => 0, logdet => -inf)\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(det):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/multiarray.py:741\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;124;03m    result_type(*arrays_and_dtypes)\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    736\u001b[0m \n\u001b[1;32m    737\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arrays_and_dtypes\n\u001b[0;32m--> 741\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mdot)\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdot\u001b[39m(a, b, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    743\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;124;03m    dot(a, b, out=None)\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    829\u001b[0m \n\u001b[1;32m    830\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, b, out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for feature in range(1,10):\n",
    "    colunas = early_warning.columns[361:]\n",
    "    \n",
    "    df = early_warning[colunas]\n",
    "    df = df.fillna(0)\n",
    "    label = pd.read_csv('ciclabel.csv')['maior_2']\n",
    "    \n",
    "    init = 202\n",
    "    end = 1484\n",
    "    \n",
    "    x_test = df[init:end]\n",
    "    y_real = label[init:end]\n",
    "    tamanho = 30\n",
    "    preds = []\n",
    "    \n",
    "    qtde_models = 0.20\n",
    "    for i in range(0, 43):\n",
    "        comeco = i*tamanho\n",
    "        final = (i+1)*tamanho\n",
    "        if(final > len(y_real)):\n",
    "            tamanho = len(y_real) - (final - tamanho) \n",
    "            final = len(y_real)\n",
    "    \n",
    "        models = 0    \n",
    "        array_kernel = ['rbf' , 'sigmoid' ] #{â€˜linearâ€™, â€˜polyâ€™, â€˜rbfâ€™, â€˜sigmoidâ€™, â€˜precomputedâ€™}\n",
    "        result = []\n",
    "    \n",
    "        x = PCA(n_components=feature, random_state=0).fit_transform(x_test[comeco:final])\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in array_kernel:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)\n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.15\n",
    "    \n",
    "    \n",
    "        learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in learning_rate:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)  \n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.15\n",
    "    \n",
    "        contamination_atual = 0.05\n",
    "        while contamination_atual <= qtde_models:\n",
    "            clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            contamination_atual += 0.01\n",
    "    \n",
    "        cols = [i for i in range(0, tamanho)]\n",
    "        df = pd.DataFrame(result, columns=[cols])\n",
    "    \n",
    "        limiar = models*0.5\n",
    "    \n",
    "        for col in cols:\n",
    "            preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "    print(\"total of features: \", feature)\n",
    "    print(confusion_matrix(y_real, preds))\n",
    "    print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d491cd-0a01-4fcf-bcaf-eecc708ea844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  1\n",
      "[[1101    2]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8602    0.9982    0.9240      1103\n",
      "           1     0.0000    0.0000    0.0000       179\n",
      "\n",
      "    accuracy                         0.8588      1282\n",
      "   macro avg     0.4301    0.4991    0.4620      1282\n",
      "weighted avg     0.7401    0.8588    0.7950      1282\n",
      "\n",
      "total of features:  2\n",
      "[[1081   22]\n",
      " [ 176    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8600    0.9801    0.9161      1103\n",
      "           1     0.1200    0.0168    0.0294       179\n",
      "\n",
      "    accuracy                         0.8456      1282\n",
      "   macro avg     0.4900    0.4984    0.4728      1282\n",
      "weighted avg     0.7567    0.8456    0.7923      1282\n",
      "\n",
      "total of features:  3\n",
      "[[1072   31]\n",
      " [ 178    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8576    0.9719    0.9112      1103\n",
      "           1     0.0312    0.0056    0.0095       179\n",
      "\n",
      "    accuracy                         0.8370      1282\n",
      "   macro avg     0.4444    0.4887    0.4603      1282\n",
      "weighted avg     0.7422    0.8370    0.7853      1282\n",
      "\n",
      "total of features:  4\n",
      "[[1064   39]\n",
      " [ 173    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8601    0.9646    0.9094      1103\n",
      "           1     0.1333    0.0335    0.0536       179\n",
      "\n",
      "    accuracy                         0.8346      1282\n",
      "   macro avg     0.4967    0.4991    0.4815      1282\n",
      "weighted avg     0.7587    0.8346    0.7899      1282\n",
      "\n",
      "total of features:  5\n",
      "[[1061   42]\n",
      " [ 175    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8584    0.9619    0.9072      1103\n",
      "           1     0.0870    0.0223    0.0356       179\n",
      "\n",
      "    accuracy                         0.8307      1282\n",
      "   macro avg     0.4727    0.4921    0.4714      1282\n",
      "weighted avg     0.7507    0.8307    0.7855      1282\n",
      "\n",
      "total of features:  6\n",
      "[[1054   49]\n",
      " [ 174    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8583    0.9556    0.9043      1103\n",
      "           1     0.0926    0.0279    0.0429       179\n",
      "\n",
      "    accuracy                         0.8261      1282\n",
      "   macro avg     0.4754    0.4918    0.4736      1282\n",
      "weighted avg     0.7514    0.8261    0.7841      1282\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2449: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  7\n",
      "[[1063   40]\n",
      " [ 174    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8593    0.9637    0.9085      1103\n",
      "           1     0.1111    0.0279    0.0446       179\n",
      "\n",
      "    accuracy                         0.8331      1282\n",
      "   macro avg     0.4852    0.4958    0.4766      1282\n",
      "weighted avg     0.7549    0.8331    0.7879      1282\n",
      "\n",
      "total of features:  8\n",
      "[[1059   44]\n",
      " [ 173    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8596    0.9601    0.9071      1103\n",
      "           1     0.1200    0.0335    0.0524       179\n",
      "\n",
      "    accuracy                         0.8307      1282\n",
      "   macro avg     0.4898    0.4968    0.4797      1282\n",
      "weighted avg     0.7563    0.8307    0.7877      1282\n",
      "\n",
      "total of features:  9\n",
      "[[1061   42]\n",
      " [ 173    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8598    0.9619    0.9080      1103\n",
      "           1     0.1250    0.0335    0.0529       179\n",
      "\n",
      "    accuracy                         0.8323      1282\n",
      "   macro avg     0.4924    0.4977    0.4804      1282\n",
      "weighted avg     0.7572    0.8323    0.7886      1282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in range(1,10):\n",
    "    colunas = early_warning.columns[361:]\n",
    "    \n",
    "    df = early_warning[colunas]\n",
    "    df = df.fillna(0)\n",
    "    label = pd.read_csv('ciclabel.csv')['maior_2']\n",
    "    \n",
    "    init = 202\n",
    "    end = 1484\n",
    "    \n",
    "    x_test = df[init:end]\n",
    "    y_real = label[init:end]\n",
    "    tamanho = 30\n",
    "    preds = []\n",
    "    \n",
    "    qtde_models = 0.30\n",
    "    for i in range(0, 43):\n",
    "        comeco = i*tamanho\n",
    "        final = (i+1)*tamanho\n",
    "        if(final > len(y_real)):\n",
    "            tamanho = len(y_real) - (final - tamanho) \n",
    "            final = len(y_real)\n",
    "    \n",
    "        models = 0    \n",
    "        array_kernel = ['rbf' , 'sigmoid' ] #{â€˜linearâ€™, â€˜polyâ€™, â€˜rbfâ€™, â€˜sigmoidâ€™, â€˜precomputedâ€™}\n",
    "        result = []\n",
    "    \n",
    "        x = PCA(n_components=feature, random_state=0).fit_transform(x_test[comeco:final])\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in array_kernel:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)\n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.05\n",
    "    \n",
    "    \n",
    "        learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in learning_rate:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)  \n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.05\n",
    "    \n",
    "        contamination_atual = 0.05\n",
    "        while contamination_atual <= qtde_models:\n",
    "            clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            contamination_atual += 0.01\n",
    "    \n",
    "        cols = [i for i in range(0, tamanho)]\n",
    "        df = pd.DataFrame(result, columns=[cols])\n",
    "    \n",
    "        limiar = models*0.5\n",
    "    \n",
    "        for col in cols:\n",
    "            preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "    print(\"total of features: \", feature)\n",
    "    print(confusion_matrix(y_real, preds))\n",
    "    print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2900a20-0f72-4285-81ef-e5508afcd45c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'early_warning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m colunas \u001b[38;5;241m=\u001b[39m \u001b[43mearly_warning\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m361\u001b[39m:]\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m early_warning[colunas]\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'early_warning' is not defined"
     ]
    }
   ],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ciclabel.csv')['maior_2']\n",
    "\n",
    "init = 202\n",
    "end = 1484\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "\n",
    "qtde_models = 0.35\n",
    "for i in range(0, 43):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['rbf' , 'sigmoid' ] #{â€˜linearâ€™, â€˜polyâ€™, â€˜rbfâ€™, â€˜sigmoidâ€™, â€˜precomputedâ€™}\n",
    "    result = []\n",
    "\n",
    "    x = PCA(n_components=3, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.15\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.15\n",
    "\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.15\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.15\n",
    "\n",
    "    contamination_atual = 0.15\n",
    "    while contamination_atual <= qtde_models:\n",
    "        clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "        y_test = clf.fit_predict(x)\n",
    "        y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "        result.append(y_test_final)  \n",
    "        models = models + 1\n",
    "        contamination_atual += 0.01\n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    limiar = models*0.5\n",
    "\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a281d9ca-295c-4eec-a658-a10fdbbda3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1061   42]\n",
      " [ 173    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8598    0.9619    0.9080      1103\n",
      "           1     0.1250    0.0335    0.0529       179\n",
      "\n",
      "    accuracy                         0.8323      1282\n",
      "   macro avg     0.4924    0.4977    0.4804      1282\n",
      "weighted avg     0.7572    0.8323    0.7886      1282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ciclabel.csv')['maior_2']\n",
    "\n",
    "init = 202\n",
    "end = 1484\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "\n",
    "qtde_models = 0.30\n",
    "for i in range(0, 43):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['rbf' , 'sigmoid' ] #{â€˜linearâ€™, â€˜polyâ€™, â€˜rbfâ€™, â€˜sigmoidâ€™, â€˜precomputedâ€™}\n",
    "    result = []\n",
    "\n",
    "    x = PCA(n_components=9, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "    contamination_atual = 0.05\n",
    "    while contamination_atual <= qtde_models:\n",
    "        clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "        y_test = clf.fit_predict(x)\n",
    "        y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "        result.append(y_test_final)  \n",
    "        models = models + 1\n",
    "        contamination_atual += 0.01\n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    limiar = models*0.5\n",
    "\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0895083d-7522-4802-b5e2-69a22a675f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
