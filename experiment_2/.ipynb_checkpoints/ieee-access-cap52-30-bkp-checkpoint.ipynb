{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bno-wuuaqwpX",
   "metadata": {
    "id": "bno-wuuaqwpX"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA, SparsePCA, MiniBatchSparsePCA\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78633f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>frame_time</th>\n",
       "      <th>total_pacotes</th>\n",
       "      <th>total_pacotes_icmp</th>\n",
       "      <th>total_pacotes_udp</th>\n",
       "      <th>total_pacotes_tcp</th>\n",
       "      <th>maior_pacote</th>\n",
       "      <th>menor_pacote</th>\n",
       "      <th>soma_pacotes</th>\n",
       "      <th>total_ips_origem</th>\n",
       "      <th>...</th>\n",
       "      <th>10_coefficient_variation_std_tcp_time_relative</th>\n",
       "      <th>10_lag-1AC_std_tcp_time_relative</th>\n",
       "      <th>10_lag-2AC_std_tcp_time_relative</th>\n",
       "      <th>10_lag-3AC_std_tcp_time_relative</th>\n",
       "      <th>10_skw_mean_tcp_time_relative</th>\n",
       "      <th>10_kurt_mean_tcp_time_relative</th>\n",
       "      <th>10_coefficient_variation_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-1AC_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-2AC_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-3AC_mean_tcp_time_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aug 18, 2011 10:39:35.087915000 -03</td>\n",
       "      <td>3802</td>\n",
       "      <td>6</td>\n",
       "      <td>420</td>\n",
       "      <td>3376</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>2808555</td>\n",
       "      <td>213</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aug 18, 2011 10:39:36.000024000 -03</td>\n",
       "      <td>3259</td>\n",
       "      <td>3</td>\n",
       "      <td>476</td>\n",
       "      <td>2780</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>2097318</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Aug 18, 2011 10:39:37.000915000 -03</td>\n",
       "      <td>3966</td>\n",
       "      <td>4</td>\n",
       "      <td>375</td>\n",
       "      <td>3587</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>2851044</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Aug 18, 2011 10:39:38.000263000 -03</td>\n",
       "      <td>3889</td>\n",
       "      <td>9</td>\n",
       "      <td>370</td>\n",
       "      <td>3508</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>2781297</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aug 18, 2011 10:39:39.000228000 -03</td>\n",
       "      <td>4077</td>\n",
       "      <td>2</td>\n",
       "      <td>362</td>\n",
       "      <td>3713</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>2923539</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>967</td>\n",
       "      <td>Aug 18, 2011 10:55:42.001011000 -03</td>\n",
       "      <td>3720</td>\n",
       "      <td>2</td>\n",
       "      <td>2999</td>\n",
       "      <td>716</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>3189759</td>\n",
       "      <td>188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125737</td>\n",
       "      <td>0.273077</td>\n",
       "      <td>0.220432</td>\n",
       "      <td>0.197854</td>\n",
       "      <td>1.035134</td>\n",
       "      <td>-0.235052</td>\n",
       "      <td>0.393167</td>\n",
       "      <td>0.677159</td>\n",
       "      <td>0.576804</td>\n",
       "      <td>0.460612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>968</td>\n",
       "      <td>Aug 18, 2011 10:55:43.000451000 -03</td>\n",
       "      <td>3567</td>\n",
       "      <td>5</td>\n",
       "      <td>2904</td>\n",
       "      <td>658</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>2992278</td>\n",
       "      <td>183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125562</td>\n",
       "      <td>0.277090</td>\n",
       "      <td>0.228485</td>\n",
       "      <td>0.205409</td>\n",
       "      <td>1.035138</td>\n",
       "      <td>-0.235039</td>\n",
       "      <td>0.393165</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.597029</td>\n",
       "      <td>0.490875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>969</td>\n",
       "      <td>Aug 18, 2011 10:55:44.000795000 -03</td>\n",
       "      <td>3515</td>\n",
       "      <td>6</td>\n",
       "      <td>2499</td>\n",
       "      <td>1009</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>2700171</td>\n",
       "      <td>209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126851</td>\n",
       "      <td>0.279146</td>\n",
       "      <td>0.222232</td>\n",
       "      <td>0.202673</td>\n",
       "      <td>1.011561</td>\n",
       "      <td>-0.390780</td>\n",
       "      <td>0.384062</td>\n",
       "      <td>0.731762</td>\n",
       "      <td>0.575967</td>\n",
       "      <td>0.479029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>970</td>\n",
       "      <td>Aug 18, 2011 10:55:45.000278000 -03</td>\n",
       "      <td>3884</td>\n",
       "      <td>7</td>\n",
       "      <td>2179</td>\n",
       "      <td>1697</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>2892316</td>\n",
       "      <td>211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126985</td>\n",
       "      <td>0.284554</td>\n",
       "      <td>0.221279</td>\n",
       "      <td>0.192221</td>\n",
       "      <td>1.055607</td>\n",
       "      <td>-0.265524</td>\n",
       "      <td>0.386897</td>\n",
       "      <td>0.728276</td>\n",
       "      <td>0.570962</td>\n",
       "      <td>0.466442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>971</td>\n",
       "      <td>Aug 18, 2011 10:55:46.001324000 -03</td>\n",
       "      <td>1309</td>\n",
       "      <td>4</td>\n",
       "      <td>1022</td>\n",
       "      <td>281</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>974374</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144581</td>\n",
       "      <td>0.281424</td>\n",
       "      <td>0.258047</td>\n",
       "      <td>0.198290</td>\n",
       "      <td>0.999001</td>\n",
       "      <td>-0.072724</td>\n",
       "      <td>0.394211</td>\n",
       "      <td>0.726038</td>\n",
       "      <td>0.558265</td>\n",
       "      <td>0.447361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972 rows × 667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                           frame_time  total_pacotes  \\\n",
       "0             0  Aug 18, 2011 10:39:35.087915000 -03           3802   \n",
       "1             1  Aug 18, 2011 10:39:36.000024000 -03           3259   \n",
       "2             2  Aug 18, 2011 10:39:37.000915000 -03           3966   \n",
       "3             3  Aug 18, 2011 10:39:38.000263000 -03           3889   \n",
       "4             4  Aug 18, 2011 10:39:39.000228000 -03           4077   \n",
       "..          ...                                  ...            ...   \n",
       "967         967  Aug 18, 2011 10:55:42.001011000 -03           3720   \n",
       "968         968  Aug 18, 2011 10:55:43.000451000 -03           3567   \n",
       "969         969  Aug 18, 2011 10:55:44.000795000 -03           3515   \n",
       "970         970  Aug 18, 2011 10:55:45.000278000 -03           3884   \n",
       "971         971  Aug 18, 2011 10:55:46.001324000 -03           1309   \n",
       "\n",
       "     total_pacotes_icmp  total_pacotes_udp  total_pacotes_tcp  maior_pacote  \\\n",
       "0                     6                420               3376          1514   \n",
       "1                     3                476               2780          1514   \n",
       "2                     4                375               3587          1514   \n",
       "3                     9                370               3508          1514   \n",
       "4                     2                362               3713          1514   \n",
       "..                  ...                ...                ...           ...   \n",
       "967                   2               2999                716          1514   \n",
       "968                   5               2904                658          1514   \n",
       "969                   6               2499               1009          1514   \n",
       "970                   7               2179               1697          1514   \n",
       "971                   4               1022                281          1514   \n",
       "\n",
       "     menor_pacote  soma_pacotes  total_ips_origem  ...  \\\n",
       "0              60       2808555               213  ...   \n",
       "1              60       2097318               203  ...   \n",
       "2              60       2851044               202  ...   \n",
       "3              60       2781297               196  ...   \n",
       "4              60       2923539               184  ...   \n",
       "..            ...           ...               ...  ...   \n",
       "967            60       3189759               188  ...   \n",
       "968            60       2992278               183  ...   \n",
       "969            60       2700171               209  ...   \n",
       "970            60       2892316               211  ...   \n",
       "971            60        974374               119  ...   \n",
       "\n",
       "     10_coefficient_variation_std_tcp_time_relative  \\\n",
       "0                                               NaN   \n",
       "1                                               NaN   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "4                                               NaN   \n",
       "..                                              ...   \n",
       "967                                        0.125737   \n",
       "968                                        0.125562   \n",
       "969                                        0.126851   \n",
       "970                                        0.126985   \n",
       "971                                        0.144581   \n",
       "\n",
       "     10_lag-1AC_std_tcp_time_relative  10_lag-2AC_std_tcp_time_relative  \\\n",
       "0                                 NaN                               NaN   \n",
       "1                                 NaN                               NaN   \n",
       "2                                 NaN                               NaN   \n",
       "3                                 NaN                               NaN   \n",
       "4                                 NaN                               NaN   \n",
       "..                                ...                               ...   \n",
       "967                          0.273077                          0.220432   \n",
       "968                          0.277090                          0.228485   \n",
       "969                          0.279146                          0.222232   \n",
       "970                          0.284554                          0.221279   \n",
       "971                          0.281424                          0.258047   \n",
       "\n",
       "     10_lag-3AC_std_tcp_time_relative  10_skw_mean_tcp_time_relative  \\\n",
       "0                                 NaN                            NaN   \n",
       "1                                 NaN                            NaN   \n",
       "2                                 NaN                            NaN   \n",
       "3                                 NaN                            NaN   \n",
       "4                                 NaN                            NaN   \n",
       "..                                ...                            ...   \n",
       "967                          0.197854                       1.035134   \n",
       "968                          0.205409                       1.035138   \n",
       "969                          0.202673                       1.011561   \n",
       "970                          0.192221                       1.055607   \n",
       "971                          0.198290                       0.999001   \n",
       "\n",
       "     10_kurt_mean_tcp_time_relative  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2                               NaN   \n",
       "3                               NaN   \n",
       "4                               NaN   \n",
       "..                              ...   \n",
       "967                       -0.235052   \n",
       "968                       -0.235039   \n",
       "969                       -0.390780   \n",
       "970                       -0.265524   \n",
       "971                       -0.072724   \n",
       "\n",
       "     10_coefficient_variation_mean_tcp_time_relative  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "..                                               ...   \n",
       "967                                         0.393167   \n",
       "968                                         0.393165   \n",
       "969                                         0.384062   \n",
       "970                                         0.386897   \n",
       "971                                         0.394211   \n",
       "\n",
       "     10_lag-1AC_mean_tcp_time_relative  10_lag-2AC_mean_tcp_time_relative  \\\n",
       "0                                  NaN                                NaN   \n",
       "1                                  NaN                                NaN   \n",
       "2                                  NaN                                NaN   \n",
       "3                                  NaN                                NaN   \n",
       "4                                  NaN                                NaN   \n",
       "..                                 ...                                ...   \n",
       "967                           0.677159                           0.576804   \n",
       "968                           0.732558                           0.597029   \n",
       "969                           0.731762                           0.575967   \n",
       "970                           0.728276                           0.570962   \n",
       "971                           0.726038                           0.558265   \n",
       "\n",
       "     10_lag-3AC_mean_tcp_time_relative  \n",
       "0                                  NaN  \n",
       "1                                  NaN  \n",
       "2                                  NaN  \n",
       "3                                  NaN  \n",
       "4                                  NaN  \n",
       "..                                 ...  \n",
       "967                           0.460612  \n",
       "968                           0.490875  \n",
       "969                           0.479029  \n",
       "970                           0.466442  \n",
       "971                           0.447361  \n",
       "\n",
       "[972 rows x 667 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_warning_url = \"early_warning_exp_2.csv\"\n",
    "early_warning = pd.read_csv(early_warning_url, sep=\";\")\n",
    "early_warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cdda222-42cc-4281-bb78-b549c00908c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[667   1]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9823    0.9985    0.9903       668\n",
      "           1     0.5000    0.0769    0.1333        13\n",
      "\n",
      "    accuracy                         0.9809       681\n",
      "   macro avg     0.7412    0.5377    0.5618       681\n",
      "weighted avg     0.9731    0.9809    0.9740       681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "\n",
    "init = 97\n",
    "end = 778\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "\n",
    "qtde_models = 0.35\n",
    "for i in range(0, 23):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['linear' , 'poly' , 'rbf' ,'sigmoid'  ] # 'precomputed'\n",
    "    result = []\n",
    "\n",
    "    x = FactorAnalysis(n_components=4, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "    array_algorithm = ['auto', 'ball_tree', 'kd_tree','brute']\n",
    "\n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    limiar = models*0.5\n",
    "\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ffdc985-ec70-4f03-bb41-26096466dd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[665   3]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9823    0.9955    0.9888       668\n",
      "           1     0.2500    0.0769    0.1176        13\n",
      "\n",
      "    accuracy                         0.9780       681\n",
      "   macro avg     0.6161    0.5362    0.5532       681\n",
      "weighted avg     0.9683    0.9780    0.9722       681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "\n",
    "init = 97\n",
    "end = 778\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "\n",
    "qtde_models = 0.35\n",
    "for i in range(0, 23):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['linear' , 'poly' , 'rbf' ,'sigmoid'  ] # 'precomputed'\n",
    "    result = []\n",
    "\n",
    "    x = FactorAnalysis(n_components=3, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "    contamination_atual = 0.05\n",
    "    while contamination_atual <= qtde_models:\n",
    "        clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "        y_test = clf.fit_predict(x)\n",
    "        y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "        result.append(y_test_final)  \n",
    "        models = models + 1\n",
    "        contamination_atual += 0.01\n",
    "\n",
    "    array_algorithm = ['auto', 'ball_tree', 'kd_tree','brute']\n",
    "\n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    limiar = models*0.5\n",
    "\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c3a594-c316-4cd4-888b-a02807ea0145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  1\n",
      "[[660   8]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9807    0.9880    0.9843       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9692       681\n",
      "   macro avg     0.4903    0.4940    0.4922       681\n",
      "weighted avg     0.9620    0.9692    0.9655       681\n",
      "\n",
      "total of features:  2\n",
      "[[645  23]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9802    0.9656    0.9729       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9471       681\n",
      "   macro avg     0.4901    0.4828    0.4864       681\n",
      "weighted avg     0.9615    0.9471    0.9543       681\n",
      "\n",
      "total of features:  3\n",
      "[[645  23]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9802    0.9656    0.9729       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9471       681\n",
      "   macro avg     0.4901    0.4828    0.4864       681\n",
      "weighted avg     0.9615    0.9471    0.9543       681\n",
      "\n",
      "total of features:  4\n",
      "[[643  25]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9817    0.9626    0.9720       668\n",
      "           1     0.0385    0.0769    0.0513        13\n",
      "\n",
      "    accuracy                         0.9457       681\n",
      "   macro avg     0.5101    0.5197    0.5117       681\n",
      "weighted avg     0.9637    0.9457    0.9545       681\n",
      "\n",
      "total of features:  5\n",
      "[[644  24]\n",
      " [ 11   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9832    0.9641    0.9735       668\n",
      "           1     0.0769    0.1538    0.1026        13\n",
      "\n",
      "    accuracy                         0.9486       681\n",
      "   macro avg     0.5301    0.5590    0.5381       681\n",
      "weighted avg     0.9659    0.9486    0.9569       681\n",
      "\n",
      "total of features:  6\n",
      "[[637  31]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9815    0.9536    0.9674       668\n",
      "           1     0.0312    0.0769    0.0444        13\n",
      "\n",
      "    accuracy                         0.9369       681\n",
      "   macro avg     0.5064    0.5153    0.5059       681\n",
      "weighted avg     0.9634    0.9369    0.9497       681\n",
      "\n",
      "total of features:  7\n",
      "[[637  31]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9815    0.9536    0.9674       668\n",
      "           1     0.0312    0.0769    0.0444        13\n",
      "\n",
      "    accuracy                         0.9369       681\n",
      "   macro avg     0.5064    0.5153    0.5059       681\n",
      "weighted avg     0.9634    0.9369    0.9497       681\n",
      "\n",
      "total of features:  8\n",
      "[[636  32]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9800    0.9521    0.9658       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9339       681\n",
      "   macro avg     0.4900    0.4760    0.4829       681\n",
      "weighted avg     0.9613    0.9339    0.9474       681\n",
      "\n",
      "total of features:  9\n",
      "[[631  37]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9798    0.9446    0.9619       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9266       681\n",
      "   macro avg     0.4899    0.4723    0.4809       681\n",
      "weighted avg     0.9611    0.9266    0.9435       681\n",
      "\n",
      "total of features:  10\n",
      "[[631  37]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9813    0.9446    0.9626       668\n",
      "           1     0.0263    0.0769    0.0392        13\n",
      "\n",
      "    accuracy                         0.9280       681\n",
      "   macro avg     0.5038    0.5108    0.5009       681\n",
      "weighted avg     0.9631    0.9280    0.9450       681\n",
      "\n",
      "total of features:  11\n",
      "[[632  36]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9814    0.9461    0.9634       668\n",
      "           1     0.0270    0.0769    0.0400        13\n",
      "\n",
      "    accuracy                         0.9295       681\n",
      "   macro avg     0.5042    0.5115    0.5017       681\n",
      "weighted avg     0.9631    0.9295    0.9458       681\n",
      "\n",
      "total of features:  12\n",
      "[[633  35]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9799    0.9476    0.9635       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9295       681\n",
      "   macro avg     0.4899    0.4738    0.4817       681\n",
      "weighted avg     0.9612    0.9295    0.9451       681\n",
      "\n",
      "total of features:  13\n",
      "[[638  30]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9815    0.9551    0.9681       668\n",
      "           1     0.0323    0.0769    0.0455        13\n",
      "\n",
      "    accuracy                         0.9383       681\n",
      "   macro avg     0.5069    0.5160    0.5068       681\n",
      "weighted avg     0.9634    0.9383    0.9505       681\n",
      "\n",
      "total of features:  14\n",
      "[[634  34]\n",
      " [ 11   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9829    0.9491    0.9657       668\n",
      "           1     0.0556    0.1538    0.0816        13\n",
      "\n",
      "    accuracy                         0.9339       681\n",
      "   macro avg     0.5193    0.5515    0.5237       681\n",
      "weighted avg     0.9652    0.9339    0.9489       681\n",
      "\n",
      "total of features:  15\n",
      "[[638  30]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9815    0.9551    0.9681       668\n",
      "           1     0.0323    0.0769    0.0455        13\n",
      "\n",
      "    accuracy                         0.9383       681\n",
      "   macro avg     0.5069    0.5160    0.5068       681\n",
      "weighted avg     0.9634    0.9383    0.9505       681\n",
      "\n",
      "total of features:  16\n",
      "[[634  34]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9814    0.9491    0.9650       668\n",
      "           1     0.0286    0.0769    0.0417        13\n",
      "\n",
      "    accuracy                         0.9325       681\n",
      "   macro avg     0.5050    0.5130    0.5033       681\n",
      "weighted avg     0.9632    0.9325    0.9474       681\n",
      "\n",
      "total of features:  17\n",
      "[[638  30]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9815    0.9551    0.9681       668\n",
      "           1     0.0323    0.0769    0.0455        13\n",
      "\n",
      "    accuracy                         0.9383       681\n",
      "   macro avg     0.5069    0.5160    0.5068       681\n",
      "weighted avg     0.9634    0.9383    0.9505       681\n",
      "\n",
      "total of features:  18\n",
      "[[635  33]\n",
      " [ 11   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9830    0.9506    0.9665       668\n",
      "           1     0.0571    0.1538    0.0833        13\n",
      "\n",
      "    accuracy                         0.9354       681\n",
      "   macro avg     0.5201    0.5522    0.5249       681\n",
      "weighted avg     0.9653    0.9354    0.9497       681\n",
      "\n",
      "total of features:  19\n",
      "[[635  33]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9815    0.9506    0.9658       668\n",
      "           1     0.0294    0.0769    0.0426        13\n",
      "\n",
      "    accuracy                         0.9339       681\n",
      "   macro avg     0.5054    0.5138    0.5042       681\n",
      "weighted avg     0.9633    0.9339    0.9482       681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in range(1,20):\n",
    "    colunas = early_warning.columns[361:]\n",
    "    df = early_warning[colunas]\n",
    "    df = df.fillna(0)\n",
    "    label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "    \n",
    "    init = 97\n",
    "    end = 778\n",
    "    \n",
    "    x_test = df[init:end]\n",
    "    y_real = label[init:end]\n",
    "    tamanho = 30\n",
    "    preds = []\n",
    "    \n",
    "    qtde_models = 0.20\n",
    "    for i in range(0, 23):\n",
    "        comeco = i*tamanho\n",
    "        final = (i+1)*tamanho\n",
    "        if(final > len(y_real)):\n",
    "            tamanho = len(y_real) - (final - tamanho) \n",
    "            final = len(y_real)\n",
    "    \n",
    "        models = 0    \n",
    "        array_kernel = ['rbf' , 'sigmoid' ] #{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}\n",
    "        result = []\n",
    "    \n",
    "        x = PCA(n_components=feature, random_state=0).fit_transform(x_test[comeco:final])\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in array_kernel:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)\n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.15\n",
    "        \n",
    "        # print('finalizou o svm')\n",
    "    \n",
    "        learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in learning_rate:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)  \n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.15\n",
    "\n",
    "        # print('finalizou o sgd')\n",
    "        \n",
    "        contamination_atual = 0.05\n",
    "        while contamination_atual <= qtde_models:\n",
    "            clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            contamination_atual += 0.01\n",
    "    \n",
    "        cols = [i for i in range(0, tamanho)]\n",
    "        df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "        # print('finalizou o eliptic')\n",
    "        \n",
    "        limiar = models*0.5\n",
    "    \n",
    "        for col in cols:\n",
    "            preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "    print(\"total of features: \", feature)\n",
    "    print(confusion_matrix(y_real, preds))\n",
    "    print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e16a9d3-c93f-4edd-a7ee-d6b4269e08d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  1\n",
      "[[667   1]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9809    0.9985    0.9896       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9794       681\n",
      "   macro avg     0.4904    0.4993    0.4948       681\n",
      "weighted avg     0.9622    0.9794    0.9707       681\n",
      "\n",
      "total of features:  2\n",
      "[[660   8]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9807    0.9880    0.9843       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9692       681\n",
      "   macro avg     0.4903    0.4940    0.4922       681\n",
      "weighted avg     0.9620    0.9692    0.9655       681\n",
      "\n",
      "total of features:  3\n",
      "[[656  12]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9806    0.9820    0.9813       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9633       681\n",
      "   macro avg     0.4903    0.4910    0.4907       681\n",
      "weighted avg     0.9618    0.9633    0.9626       681\n",
      "\n",
      "total of features:  4\n",
      "[[662   6]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9807    0.9910    0.9859       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9721       681\n",
      "   macro avg     0.4904    0.4955    0.4929       681\n",
      "weighted avg     0.9620    0.9721    0.9670       681\n",
      "\n",
      "total of features:  5\n",
      "[[660   8]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9807    0.9880    0.9843       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9692       681\n",
      "   macro avg     0.4903    0.4940    0.4922       681\n",
      "weighted avg     0.9620    0.9692    0.9655       681\n",
      "\n",
      "total of features:  6\n",
      "[[651  17]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9819    0.9746    0.9782       668\n",
      "           1     0.0556    0.0769    0.0645        13\n",
      "\n",
      "    accuracy                         0.9574       681\n",
      "   macro avg     0.5187    0.5257    0.5214       681\n",
      "weighted avg     0.9642    0.9574    0.9608       681\n",
      "\n",
      "total of features:  7\n",
      "[[649  19]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9804    0.9716    0.9759       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9530       681\n",
      "   macro avg     0.4902    0.4858    0.4880       681\n",
      "weighted avg     0.9616    0.9530    0.9573       681\n",
      "\n",
      "total of features:  8\n",
      "[[649  19]\n",
      " [ 13   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9804    0.9716    0.9759       668\n",
      "           1     0.0000    0.0000    0.0000        13\n",
      "\n",
      "    accuracy                         0.9530       681\n",
      "   macro avg     0.4902    0.4858    0.4880       681\n",
      "weighted avg     0.9616    0.9530    0.9573       681\n",
      "\n",
      "total of features:  9\n",
      "[[643  25]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9817    0.9626    0.9720       668\n",
      "           1     0.0385    0.0769    0.0513        13\n",
      "\n",
      "    accuracy                         0.9457       681\n",
      "   macro avg     0.5101    0.5197    0.5117       681\n",
      "weighted avg     0.9637    0.9457    0.9545       681\n",
      "\n",
      "total of features:  10\n",
      "[[646  22]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9818    0.9671    0.9744       668\n",
      "           1     0.0435    0.0769    0.0556        13\n",
      "\n",
      "    accuracy                         0.9501       681\n",
      "   macro avg     0.5126    0.5220    0.5150       681\n",
      "weighted avg     0.9639    0.9501    0.9568       681\n",
      "\n",
      "total of features:  11\n",
      "[[652  16]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9819    0.9760    0.9790       668\n",
      "           1     0.0588    0.0769    0.0667        13\n",
      "\n",
      "    accuracy                         0.9589       681\n",
      "   macro avg     0.5204    0.5265    0.5228       681\n",
      "weighted avg     0.9643    0.9589    0.9616       681\n",
      "\n",
      "total of features:  12\n",
      "[[650  18]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9819    0.9731    0.9774       668\n",
      "           1     0.0526    0.0769    0.0625        13\n",
      "\n",
      "    accuracy                         0.9559       681\n",
      "   macro avg     0.5173    0.5250    0.5200       681\n",
      "weighted avg     0.9641    0.9559    0.9600       681\n",
      "\n",
      "total of features:  13\n",
      "[[650  18]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9819    0.9731    0.9774       668\n",
      "           1     0.0526    0.0769    0.0625        13\n",
      "\n",
      "    accuracy                         0.9559       681\n",
      "   macro avg     0.5173    0.5250    0.5200       681\n",
      "weighted avg     0.9641    0.9559    0.9600       681\n",
      "\n",
      "total of features:  14\n",
      "[[651  17]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9819    0.9746    0.9782       668\n",
      "           1     0.0556    0.0769    0.0645        13\n",
      "\n",
      "    accuracy                         0.9574       681\n",
      "   macro avg     0.5187    0.5257    0.5214       681\n",
      "weighted avg     0.9642    0.9574    0.9608       681\n",
      "\n",
      "total of features:  15\n",
      "[[648  20]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9818    0.9701    0.9759       668\n",
      "           1     0.0476    0.0769    0.0588        13\n",
      "\n",
      "    accuracy                         0.9530       681\n",
      "   macro avg     0.5147    0.5235    0.5174       681\n",
      "weighted avg     0.9640    0.9530    0.9584       681\n",
      "\n",
      "total of features:  16\n",
      "[[651  17]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9819    0.9746    0.9782       668\n",
      "           1     0.0556    0.0769    0.0645        13\n",
      "\n",
      "    accuracy                         0.9574       681\n",
      "   macro avg     0.5187    0.5257    0.5214       681\n",
      "weighted avg     0.9642    0.9574    0.9608       681\n",
      "\n",
      "total of features:  17\n",
      "[[649  19]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9818    0.9716    0.9767       668\n",
      "           1     0.0500    0.0769    0.0606        13\n",
      "\n",
      "    accuracy                         0.9545       681\n",
      "   macro avg     0.5159    0.5242    0.5186       681\n",
      "weighted avg     0.9641    0.9545    0.9592       681\n",
      "\n",
      "total of features:  18\n",
      "[[652  16]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9819    0.9760    0.9790       668\n",
      "           1     0.0588    0.0769    0.0667        13\n",
      "\n",
      "    accuracy                         0.9589       681\n",
      "   macro avg     0.5204    0.5265    0.5228       681\n",
      "weighted avg     0.9643    0.9589    0.9616       681\n",
      "\n",
      "total of features:  19\n",
      "[[653  15]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9820    0.9775    0.9797       668\n",
      "           1     0.0625    0.0769    0.0690        13\n",
      "\n",
      "    accuracy                         0.9604       681\n",
      "   macro avg     0.5222    0.5272    0.5244       681\n",
      "weighted avg     0.9644    0.9604    0.9624       681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in range(1,20):\n",
    "    colunas = early_warning.columns[361:]\n",
    "    df = early_warning[colunas]\n",
    "    df = df.fillna(0)\n",
    "    label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "    \n",
    "    init = 97\n",
    "    end = 778\n",
    "    \n",
    "    x_test = df[init:end]\n",
    "    y_real = label[init:end]\n",
    "    tamanho = 30\n",
    "    preds = []\n",
    "    \n",
    "    qtde_models = 0.30\n",
    "    for i in range(0, 23):\n",
    "        comeco = i*tamanho\n",
    "        final = (i+1)*tamanho\n",
    "        if(final > len(y_real)):\n",
    "            tamanho = len(y_real) - (final - tamanho) \n",
    "            final = len(y_real)\n",
    "    \n",
    "        models = 0    \n",
    "        array_kernel = ['rbf' , 'sigmoid' ] #{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}\n",
    "        result = []\n",
    "    \n",
    "        x = PCA(n_components=feature, random_state=0).fit_transform(x_test[comeco:final])\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in array_kernel:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)\n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.05\n",
    "        \n",
    "        # print('finalizou o svm')\n",
    "    \n",
    "        learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in learning_rate:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)  \n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.05\n",
    "\n",
    "        # print('finalizou o sgd')\n",
    "        \n",
    "        contamination_atual = 0.05\n",
    "        while contamination_atual <= qtde_models:\n",
    "            clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            contamination_atual += 0.01\n",
    "    \n",
    "        cols = [i for i in range(0, tamanho)]\n",
    "        df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "        # print('finalizou o eliptic')\n",
    "        \n",
    "        limiar = models*0.5\n",
    "    \n",
    "        for col in cols:\n",
    "            preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "    print(\"total of features: \", feature)\n",
    "    print(confusion_matrix(y_real, preds))\n",
    "    print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f57e040-017a-4d5b-a33e-da7a791a7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d88eff84-4031-4f96-b154-0efd51753662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[648  20]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9818    0.9701    0.9759       668\n",
      "           1     0.0476    0.0769    0.0588        13\n",
      "\n",
      "    accuracy                         0.9530       681\n",
      "   macro avg     0.5147    0.5235    0.5174       681\n",
      "weighted avg     0.9640    0.9530    0.9584       681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "\n",
    "init = 97\n",
    "end = 778\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "\n",
    "qtde_models = 0.35\n",
    "for i in range(0, 23):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['rbf' , 'sigmoid' ] #{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}\n",
    "    result = []\n",
    "\n",
    "    x = PCA(n_components=3, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.15\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.15\n",
    "    \n",
    "    # print('finalizou o svm')\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.15\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.15\n",
    "\n",
    "    # print('finalizou o sgd')\n",
    "    \n",
    "    contamination_atual = 0.15\n",
    "    while contamination_atual <= qtde_models:\n",
    "        clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "        y_test = clf.fit_predict(x)\n",
    "        y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "        result.append(y_test_final)  \n",
    "        models = models + 1\n",
    "        contamination_atual += 0.01\n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    # print('finalizou o eliptic')\n",
    "    \n",
    "    limiar = models*0.5\n",
    "\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e8c33da-eb1a-4fa5-8a16-a1fa6c106da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[643  25]\n",
      " [ 12   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9817    0.9626    0.9720       668\n",
      "           1     0.0385    0.0769    0.0513        13\n",
      "\n",
      "    accuracy                         0.9457       681\n",
      "   macro avg     0.5101    0.5197    0.5117       681\n",
      "weighted avg     0.9637    0.9457    0.9545       681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "\n",
    "init = 97\n",
    "end = 778\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "\n",
    "qtde_models = 0.30\n",
    "for i in range(0, 23):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['rbf' , 'sigmoid' ] #{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}\n",
    "    result = []\n",
    "\n",
    "    x = PCA(n_components=9, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "    \n",
    "    # print('finalizou o svm')\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "    # print('finalizou o sgd')\n",
    "    \n",
    "    contamination_atual = 0.05\n",
    "    while contamination_atual <= qtde_models:\n",
    "        clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "        y_test = clf.fit_predict(x)\n",
    "        y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "        result.append(y_test_final)  \n",
    "        models = models + 1\n",
    "        contamination_atual += 0.01\n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    # print('finalizou o eliptic')\n",
    "    \n",
    "    limiar = models*0.5\n",
    "\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16141869-e77e-4549-bb37-2342bc4bee9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
