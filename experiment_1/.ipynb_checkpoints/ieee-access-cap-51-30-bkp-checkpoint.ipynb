{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bno-wuuaqwpX",
   "metadata": {
    "id": "bno-wuuaqwpX"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78633f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>frame_time</th>\n",
       "      <th>total_pacotes</th>\n",
       "      <th>total_pacotes_icmp</th>\n",
       "      <th>total_pacotes_udp</th>\n",
       "      <th>total_pacotes_tcp</th>\n",
       "      <th>maior_pacote</th>\n",
       "      <th>menor_pacote</th>\n",
       "      <th>soma_pacotes</th>\n",
       "      <th>total_ips_origem</th>\n",
       "      <th>...</th>\n",
       "      <th>10_coefficient_variation_std_tcp_time_relative</th>\n",
       "      <th>10_lag-1AC_std_tcp_time_relative</th>\n",
       "      <th>10_lag-2AC_std_tcp_time_relative</th>\n",
       "      <th>10_lag-3AC_std_tcp_time_relative</th>\n",
       "      <th>10_skw_mean_tcp_time_relative</th>\n",
       "      <th>10_kurt_mean_tcp_time_relative</th>\n",
       "      <th>10_coefficient_variation_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-1AC_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-2AC_mean_tcp_time_relative</th>\n",
       "      <th>10_lag-3AC_mean_tcp_time_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aug 18, 2011 08:19:13.328377000 UTC</td>\n",
       "      <td>1343</td>\n",
       "      <td>1</td>\n",
       "      <td>597</td>\n",
       "      <td>710</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>1063048</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aug 18, 2011 08:19:14.001200000 UTC</td>\n",
       "      <td>1829</td>\n",
       "      <td>4</td>\n",
       "      <td>764</td>\n",
       "      <td>978</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>1352117</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Aug 18, 2011 08:19:15.005031000 UTC</td>\n",
       "      <td>1794</td>\n",
       "      <td>4</td>\n",
       "      <td>859</td>\n",
       "      <td>888</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>1274290</td>\n",
       "      <td>183</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Aug 18, 2011 08:19:16.004984000 UTC</td>\n",
       "      <td>1797</td>\n",
       "      <td>3</td>\n",
       "      <td>643</td>\n",
       "      <td>1110</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>1244046</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aug 18, 2011 08:19:17.000069000 UTC</td>\n",
       "      <td>2047</td>\n",
       "      <td>5</td>\n",
       "      <td>889</td>\n",
       "      <td>1104</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>1415830</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8798</th>\n",
       "      <td>8798</td>\n",
       "      <td>Aug 18, 2011 10:45:51.000139000 UTC</td>\n",
       "      <td>13063</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>12729</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>12434675</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198314</td>\n",
       "      <td>0.373041</td>\n",
       "      <td>0.188673</td>\n",
       "      <td>0.228270</td>\n",
       "      <td>-0.778374</td>\n",
       "      <td>1.919347</td>\n",
       "      <td>0.295774</td>\n",
       "      <td>0.547461</td>\n",
       "      <td>0.455502</td>\n",
       "      <td>0.467108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8799</th>\n",
       "      <td>8799</td>\n",
       "      <td>Aug 18, 2011 10:45:52.001829000 UTC</td>\n",
       "      <td>11448</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>11160</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>10711927</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198197</td>\n",
       "      <td>0.372345</td>\n",
       "      <td>0.187880</td>\n",
       "      <td>0.227413</td>\n",
       "      <td>-0.779524</td>\n",
       "      <td>1.925385</td>\n",
       "      <td>0.295608</td>\n",
       "      <td>0.546494</td>\n",
       "      <td>0.455061</td>\n",
       "      <td>0.466422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8800</th>\n",
       "      <td>8800</td>\n",
       "      <td>Aug 18, 2011 10:45:53.000249000 UTC</td>\n",
       "      <td>19537</td>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "      <td>19158</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>18804518</td>\n",
       "      <td>194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197878</td>\n",
       "      <td>0.370958</td>\n",
       "      <td>0.186528</td>\n",
       "      <td>0.227835</td>\n",
       "      <td>-0.772473</td>\n",
       "      <td>1.925770</td>\n",
       "      <td>0.295801</td>\n",
       "      <td>0.547163</td>\n",
       "      <td>0.453754</td>\n",
       "      <td>0.467004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8801</th>\n",
       "      <td>8801</td>\n",
       "      <td>Aug 18, 2011 10:45:54.000253000 UTC</td>\n",
       "      <td>23437</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>23186</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>22579857</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197621</td>\n",
       "      <td>0.370033</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.225963</td>\n",
       "      <td>-0.772488</td>\n",
       "      <td>1.939248</td>\n",
       "      <td>0.295409</td>\n",
       "      <td>0.547758</td>\n",
       "      <td>0.454853</td>\n",
       "      <td>0.465247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8802</th>\n",
       "      <td>8802</td>\n",
       "      <td>Aug 18, 2011 10:45:55.000156000 UTC</td>\n",
       "      <td>8556</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>8430</td>\n",
       "      <td>1514</td>\n",
       "      <td>60</td>\n",
       "      <td>8313828</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198786</td>\n",
       "      <td>0.367613</td>\n",
       "      <td>0.183959</td>\n",
       "      <td>0.221747</td>\n",
       "      <td>-0.772755</td>\n",
       "      <td>1.933245</td>\n",
       "      <td>0.295589</td>\n",
       "      <td>0.542083</td>\n",
       "      <td>0.447020</td>\n",
       "      <td>0.458861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8803 rows × 667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                           frame_time  total_pacotes  \\\n",
       "0              0  Aug 18, 2011 08:19:13.328377000 UTC           1343   \n",
       "1              1  Aug 18, 2011 08:19:14.001200000 UTC           1829   \n",
       "2              2  Aug 18, 2011 08:19:15.005031000 UTC           1794   \n",
       "3              3  Aug 18, 2011 08:19:16.004984000 UTC           1797   \n",
       "4              4  Aug 18, 2011 08:19:17.000069000 UTC           2047   \n",
       "...          ...                                  ...            ...   \n",
       "8798        8798  Aug 18, 2011 10:45:51.000139000 UTC          13063   \n",
       "8799        8799  Aug 18, 2011 10:45:52.001829000 UTC          11448   \n",
       "8800        8800  Aug 18, 2011 10:45:53.000249000 UTC          19537   \n",
       "8801        8801  Aug 18, 2011 10:45:54.000253000 UTC          23437   \n",
       "8802        8802  Aug 18, 2011 10:45:55.000156000 UTC           8556   \n",
       "\n",
       "      total_pacotes_icmp  total_pacotes_udp  total_pacotes_tcp  maior_pacote  \\\n",
       "0                      1                597                710          1514   \n",
       "1                      4                764                978          1514   \n",
       "2                      4                859                888          1514   \n",
       "3                      3                643               1110          1514   \n",
       "4                      5                889               1104          1514   \n",
       "...                  ...                ...                ...           ...   \n",
       "8798                   0                271              12729          1514   \n",
       "8799                   0                223              11160          1514   \n",
       "8800                   0                332              19158          1514   \n",
       "8801                   0                234              23186          1514   \n",
       "8802                   0                 89               8430          1514   \n",
       "\n",
       "      menor_pacote  soma_pacotes  total_ips_origem  ...  \\\n",
       "0               60       1063048               108  ...   \n",
       "1               60       1352117               145  ...   \n",
       "2               60       1274290               183  ...   \n",
       "3               60       1244046               159  ...   \n",
       "4               60       1415830               176  ...   \n",
       "...            ...           ...               ...  ...   \n",
       "8798            60      12434675               193  ...   \n",
       "8799            60      10711927               149  ...   \n",
       "8800            60      18804518               194  ...   \n",
       "8801            60      22579857               139  ...   \n",
       "8802            60       8313828                89  ...   \n",
       "\n",
       "      10_coefficient_variation_std_tcp_time_relative  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "...                                              ...   \n",
       "8798                                        0.198314   \n",
       "8799                                        0.198197   \n",
       "8800                                        0.197878   \n",
       "8801                                        0.197621   \n",
       "8802                                        0.198786   \n",
       "\n",
       "      10_lag-1AC_std_tcp_time_relative  10_lag-2AC_std_tcp_time_relative  \\\n",
       "0                                  NaN                               NaN   \n",
       "1                                  NaN                               NaN   \n",
       "2                                  NaN                               NaN   \n",
       "3                                  NaN                               NaN   \n",
       "4                                  NaN                               NaN   \n",
       "...                                ...                               ...   \n",
       "8798                          0.373041                          0.188673   \n",
       "8799                          0.372345                          0.187880   \n",
       "8800                          0.370958                          0.186528   \n",
       "8801                          0.370033                          0.186868   \n",
       "8802                          0.367613                          0.183959   \n",
       "\n",
       "      10_lag-3AC_std_tcp_time_relative  10_skw_mean_tcp_time_relative  \\\n",
       "0                                  NaN                            NaN   \n",
       "1                                  NaN                            NaN   \n",
       "2                                  NaN                            NaN   \n",
       "3                                  NaN                            NaN   \n",
       "4                                  NaN                            NaN   \n",
       "...                                ...                            ...   \n",
       "8798                          0.228270                      -0.778374   \n",
       "8799                          0.227413                      -0.779524   \n",
       "8800                          0.227835                      -0.772473   \n",
       "8801                          0.225963                      -0.772488   \n",
       "8802                          0.221747                      -0.772755   \n",
       "\n",
       "      10_kurt_mean_tcp_time_relative  \\\n",
       "0                                NaN   \n",
       "1                                NaN   \n",
       "2                                NaN   \n",
       "3                                NaN   \n",
       "4                                NaN   \n",
       "...                              ...   \n",
       "8798                        1.919347   \n",
       "8799                        1.925385   \n",
       "8800                        1.925770   \n",
       "8801                        1.939248   \n",
       "8802                        1.933245   \n",
       "\n",
       "      10_coefficient_variation_mean_tcp_time_relative  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "...                                               ...   \n",
       "8798                                         0.295774   \n",
       "8799                                         0.295608   \n",
       "8800                                         0.295801   \n",
       "8801                                         0.295409   \n",
       "8802                                         0.295589   \n",
       "\n",
       "      10_lag-1AC_mean_tcp_time_relative  10_lag-2AC_mean_tcp_time_relative  \\\n",
       "0                                   NaN                                NaN   \n",
       "1                                   NaN                                NaN   \n",
       "2                                   NaN                                NaN   \n",
       "3                                   NaN                                NaN   \n",
       "4                                   NaN                                NaN   \n",
       "...                                 ...                                ...   \n",
       "8798                           0.547461                           0.455502   \n",
       "8799                           0.546494                           0.455061   \n",
       "8800                           0.547163                           0.453754   \n",
       "8801                           0.547758                           0.454853   \n",
       "8802                           0.542083                           0.447020   \n",
       "\n",
       "      10_lag-3AC_mean_tcp_time_relative  \n",
       "0                                   NaN  \n",
       "1                                   NaN  \n",
       "2                                   NaN  \n",
       "3                                   NaN  \n",
       "4                                   NaN  \n",
       "...                                 ...  \n",
       "8798                           0.467108  \n",
       "8799                           0.466422  \n",
       "8800                           0.467004  \n",
       "8801                           0.465247  \n",
       "8802                           0.458861  \n",
       "\n",
       "[8803 rows x 667 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_warning_url = \"early_warning_exp_1.csv\"\n",
    "early_warning = pd.read_csv(early_warning_url, sep=\";\")\n",
    "early_warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b58c6b5-2541-4898-96f8-6a6269ec44f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4664   36]\n",
      " [  51    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9892    0.9923    0.9908      4700\n",
      "           1     0.0270    0.0192    0.0225        52\n",
      "\n",
      "    accuracy                         0.9817      4752\n",
      "   macro avg     0.5081    0.5058    0.5066      4752\n",
      "weighted avg     0.9787    0.9817    0.9802      4752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "\n",
    "init = 880\n",
    "end = 5632\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "models = 0\n",
    "\n",
    "qtde_models = 0.35\n",
    "for i in range(0, 159):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['linear' , 'poly' , 'rbf' ,'sigmoid'  ]\n",
    "    result = []\n",
    "\n",
    "    x = FactorAnalysis(n_components=1, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            models = models + 1\n",
    "            result.append(y_test_final)  \n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "    array_algorithm = ['auto', 'ball_tree', 'kd_tree','brute']\n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    limiar = models*0.5\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e96a718-4034-4c26-8f9c-67124a7ea9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4589  111]\n",
      " [  51    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9890    0.9764    0.9827      4700\n",
      "           1     0.0089    0.0192    0.0122        52\n",
      "\n",
      "    accuracy                         0.9659      4752\n",
      "   macro avg     0.4990    0.4978    0.4974      4752\n",
      "weighted avg     0.9783    0.9659    0.9720      4752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "\n",
    "init = 880\n",
    "end = 5632\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "models = 0\n",
    "\n",
    "qtde_models = 0.35\n",
    "for i in range(0, 159):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['linear' , 'poly' , 'rbf' ,'sigmoid'  ]\n",
    "    result = []\n",
    "\n",
    "    x = FactorAnalysis(n_components=1, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            models = models + 1\n",
    "            result.append(y_test_final)  \n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "    \n",
    "    contamination_atual = 0.05\n",
    "    while contamination_atual <= qtde_models:\n",
    "        clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "        y_test = clf.fit_predict(x)\n",
    "        y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "        result.append(y_test_final)  \n",
    "        models = models + 1\n",
    "        contamination_atual += 0.01\n",
    "\n",
    "    array_algorithm = ['auto', 'ball_tree', 'kd_tree','brute']\n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    limiar = models*0.5\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157c88a5-45f4-4ab3-bd7a-b42ca9bad096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  1\n",
      "[[4580  120]\n",
      " [  51    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9890    0.9745    0.9817      4700\n",
      "           1     0.0083    0.0192    0.0116        52\n",
      "\n",
      "    accuracy                         0.9640      4752\n",
      "   macro avg     0.4986    0.4968    0.4966      4752\n",
      "weighted avg     0.9783    0.9640    0.9711      4752\n",
      "\n",
      "total of features:  2\n",
      "[[4600  100]\n",
      " [  51    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9890    0.9787    0.9839      4700\n",
      "           1     0.0099    0.0192    0.0131        52\n",
      "\n",
      "    accuracy                         0.9682      4752\n",
      "   macro avg     0.4995    0.4990    0.4985      4752\n",
      "weighted avg     0.9783    0.9682    0.9732      4752\n",
      "\n",
      "total of features:  3\n",
      "[[4585  115]\n",
      " [  51    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9890    0.9755    0.9822      4700\n",
      "           1     0.0086    0.0192    0.0119        52\n",
      "\n",
      "    accuracy                         0.9651      4752\n",
      "   macro avg     0.4988    0.4974    0.4971      4752\n",
      "weighted avg     0.9783    0.9651    0.9716      4752\n",
      "\n",
      "total of features:  4\n",
      "[[4586  114]\n",
      " [  52    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9888    0.9757    0.9822      4700\n",
      "           1     0.0000    0.0000    0.0000        52\n",
      "\n",
      "    accuracy                         0.9651      4752\n",
      "   macro avg     0.4944    0.4879    0.4911      4752\n",
      "weighted avg     0.9780    0.9651    0.9715      4752\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m nu_atual \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m qtde_models:\n\u001b[1;32m     47\u001b[0m     clf \u001b[38;5;241m=\u001b[39m SGDOneClassSVM(learning_rate \u001b[38;5;241m=\u001b[39m c, nu \u001b[38;5;241m=\u001b[39m nu_atual, eta0\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     y_test_final \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m y_test]\n\u001b[1;32m     50\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(y_test_final)  \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1036\u001b[0m, in \u001b[0;36mOutlierMixin.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Perform fit on X and returns labels for X.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \n\u001b[1;32m   1020\u001b[0m \u001b[38;5;124;03mReturns -1 for outliers and 1 for inliers.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;124;03m    1 for inliers, -1 for outliers.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m# override for transductive outlier detectors like LocalOulierFactor\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2496\u001b[0m, in \u001b[0;36mSGDOneClassSVM.fit\u001b[0;34m(self, X, y, coef_init, offset_init, sample_weight)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_more_validate_params()\n\u001b[1;32m   2495\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2498\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2504\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2432\u001b[0m, in \u001b[0;36mSGDOneClassSVM._fit\u001b[0;34m(self, X, alpha, C, loss, learning_rate, coef_init, offset_init, sample_weight)\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[38;5;66;03m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[1;32m   2430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m-> 2432\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2434\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2438\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2439\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2441\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2446\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m   2447\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[1;32m   2448\u001b[0m ):\n\u001b[1;32m   2449\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2450\u001b[0m         (\n\u001b[1;32m   2451\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum number of iteration reached before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2455\u001b[0m         ConvergenceWarning,\n\u001b[1;32m   2456\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2362\u001b[0m, in \u001b[0;36mSGDOneClassSVM._partial_fit\u001b[0;34m(self, X, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, offset_init)\u001b[0m\n\u001b[1;32m   2359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m   2361\u001b[0m \u001b[38;5;66;03m# delegate to concrete training procedure\u001b[39;00m\n\u001b[0;32m-> 2362\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_one_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2364\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2233\u001b[0m, in \u001b[0;36mSGDOneClassSVM._fit_one_class\u001b[0;34m(self, X, alpha, C, sample_weight, learning_rate, max_iter)\u001b[0m\n\u001b[1;32m   2228\u001b[0m validation_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_validation_split(y, sample_mask\u001b[38;5;241m=\u001b[39msample_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2229\u001b[0m validation_score_cb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_validation_score_cb(\n\u001b[1;32m   2230\u001b[0m     validation_mask, X, y, sample_weight\n\u001b[1;32m   2231\u001b[0m )\n\u001b[0;32m-> 2233\u001b[0m random_state \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_random_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;66;03m# numpy mtrand expects a C long which is a signed 32 bit integer under\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;66;03m# Windows\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m seed \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1268\u001b[0m, in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmtrand\u001b[38;5;241m.\u001b[39m_rand\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[0;32m-> 1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomState\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seed, np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState):\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m seed\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:184\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mt19937.pyx:132\u001b[0m, in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for feature in range(1,10):\n",
    "    colunas = early_warning.columns[361:]\n",
    "    \n",
    "    df = early_warning[colunas]\n",
    "    df = df.fillna(0)\n",
    "    label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "    \n",
    "    init = 880\n",
    "    end = 5632\n",
    "    \n",
    "    x_test = df[init:end]\n",
    "    y_real = label[init:end]\n",
    "    tamanho = 30\n",
    "    preds = []\n",
    "    \n",
    "    qtde_models = 0.20\n",
    "    for i in range(0, 159):\n",
    "        comeco = i*tamanho\n",
    "        final = (i+1)*tamanho\n",
    "        if(final > len(y_real)):\n",
    "            tamanho = len(y_real) - (final - tamanho) \n",
    "            final = len(y_real)\n",
    "    \n",
    "        models = 0    \n",
    "        array_kernel = ['rbf' , 'sigmoid' ] #{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}\n",
    "        result = []\n",
    "    \n",
    "        x = PCA(n_components=feature, random_state=0).fit_transform(x_test[comeco:final])\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in array_kernel:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)\n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.15\n",
    "    \n",
    "    \n",
    "        learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in learning_rate:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)  \n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.15\n",
    "    \n",
    "        contamination_atual = 0.05\n",
    "        while contamination_atual <= qtde_models:\n",
    "            clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            contamination_atual += 0.01\n",
    "    \n",
    "    \n",
    "        cols = [i for i in range(0, tamanho)]\n",
    "        df = pd.DataFrame(result, columns=[cols])\n",
    "    \n",
    "        limiar = models*0.5\n",
    "    \n",
    "    \n",
    "        for col in cols:\n",
    "            preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "    print(\"total of features: \", feature)\n",
    "    print(confusion_matrix(y_real, preds))\n",
    "    print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be6395c2-e663-4cfb-b818-26b546280a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  1\n",
      "[[4657   43]\n",
      " [  51    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9892    0.9909    0.9900      4700\n",
      "           1     0.0227    0.0192    0.0208        52\n",
      "\n",
      "    accuracy                         0.9802      4752\n",
      "   macro avg     0.5059    0.5050    0.5054      4752\n",
      "weighted avg     0.9786    0.9802    0.9794      4752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2449: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2449: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2449: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2449: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  2\n",
      "[[4625   75]\n",
      " [  52    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9889    0.9840    0.9865      4700\n",
      "           1     0.0000    0.0000    0.0000        52\n",
      "\n",
      "    accuracy                         0.9733      4752\n",
      "   macro avg     0.4944    0.4920    0.4932      4752\n",
      "weighted avg     0.9781    0.9733    0.9757      4752\n",
      "\n",
      "total of features:  3\n",
      "[[4601   99]\n",
      " [  50    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9892    0.9789    0.9841      4700\n",
      "           1     0.0198    0.0385    0.0261        52\n",
      "\n",
      "    accuracy                         0.9686      4752\n",
      "   macro avg     0.5045    0.5087    0.5051      4752\n",
      "weighted avg     0.9786    0.9686    0.9736      4752\n",
      "\n",
      "total of features:  4\n",
      "[[4591  109]\n",
      " [  50    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9892    0.9768    0.9830      4700\n",
      "           1     0.0180    0.0385    0.0245        52\n",
      "\n",
      "    accuracy                         0.9665      4752\n",
      "   macro avg     0.5036    0.5076    0.5038      4752\n",
      "weighted avg     0.9786    0.9665    0.9725      4752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2449: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  5\n",
      "[[4576  124]\n",
      " [  50    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9892    0.9736    0.9813      4700\n",
      "           1     0.0159    0.0385    0.0225        52\n",
      "\n",
      "    accuracy                         0.9634      4752\n",
      "   macro avg     0.5025    0.5060    0.5019      4752\n",
      "weighted avg     0.9785    0.9634    0.9708      4752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2449: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  6\n",
      "[[4582  118]\n",
      " [  50    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9892    0.9749    0.9820      4700\n",
      "           1     0.0167    0.0385    0.0233        52\n",
      "\n",
      "    accuracy                         0.9646      4752\n",
      "   macro avg     0.5029    0.5067    0.5026      4752\n",
      "weighted avg     0.9786    0.9646    0.9715      4752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2449: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  7\n",
      "[[4585  115]\n",
      " [  50    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9892    0.9755    0.9823      4700\n",
      "           1     0.0171    0.0385    0.0237        52\n",
      "\n",
      "    accuracy                         0.9653      4752\n",
      "   macro avg     0.5032    0.5070    0.5030      4752\n",
      "weighted avg     0.9786    0.9653    0.9718      4752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2449: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  8\n",
      "[[4577  123]\n",
      " [  50    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9892    0.9738    0.9815      4700\n",
      "           1     0.0160    0.0385    0.0226        52\n",
      "\n",
      "    accuracy                         0.9636      4752\n",
      "   macro avg     0.5026    0.5061    0.5020      4752\n",
      "weighted avg     0.9785    0.9636    0.9710      4752\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2449: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of features:  9\n",
      "[[4575  125]\n",
      " [  50    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9892    0.9734    0.9812      4700\n",
      "           1     0.0157    0.0385    0.0223        52\n",
      "\n",
      "    accuracy                         0.9632      4752\n",
      "   macro avg     0.5025    0.5059    0.5018      4752\n",
      "weighted avg     0.9785    0.9632    0.9707      4752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in range(1,10):\n",
    "    colunas = early_warning.columns[361:]\n",
    "    \n",
    "    df = early_warning[colunas]\n",
    "    df = df.fillna(0)\n",
    "    label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "    \n",
    "    init = 880\n",
    "    end = 5632\n",
    "    \n",
    "    x_test = df[init:end]\n",
    "    y_real = label[init:end]\n",
    "    tamanho = 30\n",
    "    preds = []\n",
    "    \n",
    "    qtde_models = 0.30\n",
    "    for i in range(0, 159):\n",
    "        comeco = i*tamanho\n",
    "        final = (i+1)*tamanho\n",
    "        if(final > len(y_real)):\n",
    "            tamanho = len(y_real) - (final - tamanho) \n",
    "            final = len(y_real)\n",
    "    \n",
    "        models = 0    \n",
    "        array_kernel = ['rbf' , 'sigmoid' ] #{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}\n",
    "        result = []\n",
    "    \n",
    "        x = PCA(n_components=feature, random_state=0).fit_transform(x_test[comeco:final])\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in array_kernel:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)\n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.05\n",
    "    \n",
    "    \n",
    "        learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "    \n",
    "        nu_atual = 0.05\n",
    "        for c in learning_rate:\n",
    "            while nu_atual <= qtde_models:\n",
    "                clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "                y_test = clf.fit_predict(x)\n",
    "                y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "                result.append(y_test_final)  \n",
    "                models = models + 1\n",
    "                nu_atual += 0.01\n",
    "            nu_atual = 0.05\n",
    "    \n",
    "        contamination_atual = 0.05\n",
    "        while contamination_atual <= qtde_models:\n",
    "            clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            contamination_atual += 0.01\n",
    "    \n",
    "    \n",
    "        cols = [i for i in range(0, tamanho)]\n",
    "        df = pd.DataFrame(result, columns=[cols])\n",
    "    \n",
    "        limiar = models*0.5\n",
    "    \n",
    "    \n",
    "        for col in cols:\n",
    "            preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "    print(\"total of features: \", feature)\n",
    "    print(confusion_matrix(y_real, preds))\n",
    "    print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f3e3ca-edd2-430d-8fa8-1d80c52e3e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4480  220]\n",
      " [  50    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9890    0.9532    0.9707      4700\n",
      "           1     0.0090    0.0385    0.0146        52\n",
      "\n",
      "    accuracy                         0.9432      4752\n",
      "   macro avg     0.4990    0.4958    0.4927      4752\n",
      "weighted avg     0.9782    0.9432    0.9603      4752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunas = early_warning.columns[361:]\n",
    "\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "\n",
    "init = 880\n",
    "end = 5632\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "\n",
    "qtde_models = 0.35\n",
    "for i in range(0, 159):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['rbf' , 'sigmoid' ] #{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}\n",
    "    result = []\n",
    "\n",
    "    x = PCA(n_components=3, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.15\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.15\n",
    "\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.15\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.15\n",
    "\n",
    "    contamination_atual = 0.15\n",
    "    while contamination_atual <= qtde_models:\n",
    "        clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "        y_test = clf.fit_predict(x)\n",
    "        y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "        result.append(y_test_final)  \n",
    "        models = models + 1\n",
    "        contamination_atual += 0.01\n",
    "\n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    limiar = models*0.5\n",
    "\n",
    "\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "print(\"total of features: \", feature)\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f755e-17bf-4c24-b5b2-661e6e4dce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson-note/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:2449: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "colunas = early_warning.columns[361:]\n",
    "\n",
    "df = early_warning[colunas]\n",
    "df = df.fillna(0)\n",
    "label = pd.read_csv('ctulabel.csv')['maior_2']\n",
    "\n",
    "init = 880\n",
    "end = 5632\n",
    "\n",
    "x_test = df[init:end]\n",
    "y_real = label[init:end]\n",
    "tamanho = 30\n",
    "preds = []\n",
    "\n",
    "qtde_models = 0.30\n",
    "for i in range(0, 159):\n",
    "    comeco = i*tamanho\n",
    "    final = (i+1)*tamanho\n",
    "    if(final > len(y_real)):\n",
    "        tamanho = len(y_real) - (final - tamanho) \n",
    "        final = len(y_real)\n",
    "\n",
    "    models = 0    \n",
    "    array_kernel = ['rbf' , 'sigmoid' ] #{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}\n",
    "    result = []\n",
    "\n",
    "    x = PCA(n_components=9, random_state=0).fit_transform(x_test[comeco:final])\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in array_kernel:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)\n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "\n",
    "    learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
    "\n",
    "    nu_atual = 0.05\n",
    "    for c in learning_rate:\n",
    "        while nu_atual <= qtde_models:\n",
    "            clf = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0)\n",
    "            y_test = clf.fit_predict(x)\n",
    "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "            result.append(y_test_final)  \n",
    "            models = models + 1\n",
    "            nu_atual += 0.01\n",
    "        nu_atual = 0.05\n",
    "\n",
    "    contamination_atual = 0.05\n",
    "    while contamination_atual <= qtde_models:\n",
    "        clf = EllipticEnvelope(contamination = contamination_atual,support_fraction=1, random_state=0)\n",
    "        y_test = clf.fit_predict(x)\n",
    "        y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
    "        result.append(y_test_final)  \n",
    "        models = models + 1\n",
    "        contamination_atual += 0.01\n",
    "\n",
    "\n",
    "    cols = [i for i in range(0, tamanho)]\n",
    "    df = pd.DataFrame(result, columns=[cols])\n",
    "\n",
    "    limiar = models*0.5\n",
    "\n",
    "\n",
    "    for col in cols:\n",
    "        preds.append(1 if (df[col].sum()[col] > limiar) else 0)\n",
    "\n",
    "print(confusion_matrix(y_real, preds))\n",
    "print(classification_report(y_real, preds, digits = 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0074e1cb-c79f-4c5b-b863-cdb3f4e7248e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
